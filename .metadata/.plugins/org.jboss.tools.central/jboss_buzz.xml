<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Deploying Kubernetes Operators with Operator Lifecycle Manager bundles</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Fz4zpPjv0vk/" /><category term="Go" /><category term="Kubernetes" /><category term="Operator" /><category term="OLM bundles" /><category term="operator framework" /><category term="Operator Lifecycle Manager" /><category term="operator-sdk" /><author><name>Jeff McCormick</name></author><id>https://developers.redhat.com/blog/?p=798747</id><updated>2021-02-08T08:00:18Z</updated><published>2021-02-08T08:00:18Z</published><content type="html">&lt;p&gt;This article shows an example of using the &lt;a target="_blank" rel="nofollow" href="https://olm.operatorframework.io/"&gt;Operator Lifecycle Manager&lt;/a&gt; (OLM) bundle deployment architecture to deploy a &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt; or other &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; Operator. You will learn how to use OLM and the &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/"&gt;Operator SDK&lt;/a&gt; (both components of the Kubernetes &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework"&gt;Operator Framework&lt;/a&gt;) together to deploy an Operator.&lt;/p&gt; &lt;h2&gt;About the example&lt;/h2&gt; &lt;p&gt;I tested the Operator Lifecycle Manager example on both an OpenShift 4.6 cluster (via &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt;) and a local Kubernetes &lt;a target="_blank" rel="nofollow" href="https://kind.sigs.k8s.io/"&gt;Kind 1.18&lt;/a&gt; cluster. I used &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/"&gt;Operator SDK 1.0&lt;/a&gt; and OLM 0.15.0 for this example.&lt;/p&gt; &lt;h2&gt;Scaffolding the Operator&lt;/h2&gt; &lt;p&gt;A &lt;em&gt;bundle&lt;/em&gt; is an Operator packaging construct that contains an Operator definition and manifests used to determine how the Operator is deployed onto a Kubernetes cluster. The original OLM package manifest format has migrated to the bundle format.&lt;/p&gt; &lt;p&gt;In this example, we will use &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/"&gt;Operator SDK&lt;/a&gt; 1.0 to generate an Operator bundle and create the Operator for deployment. Enter the following &lt;code&gt;operator-sdk&lt;/code&gt; commands to begin scaffolding the sample Operator:&lt;/p&gt; &lt;pre&gt;$ operator-sdk init --domain=example.com --repo=github.com/example-inc/doo-operator $ operator-sdk create api --group cache --version v1 --kind Doo --resource=true --controller=true &lt;/pre&gt; &lt;h2&gt;Working with container images in Operator SDK&lt;/h2&gt; &lt;p&gt;When &lt;code&gt;operator-sdk&lt;/code&gt; generates or scaffolds an Operator, it does not include any logic about your application. You will need to include information about how to install and manage your application. Like any other Operator, the resulting code is built into a container image. In this example, the Operator image is named &lt;code&gt;quay.io/username/doo-operator:v0.0.1&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Entering the &lt;code&gt;operator-sdk init&lt;/code&gt; command creates a project structure. This command also creates a Makefile that you can use for various build and deployment tasks. Enter the following to build an Operator image using a Makefile:&lt;/p&gt; &lt;pre&gt;$ make docker-build docker-push IMG=quay.io/username/doo-operator:v0.0.1 &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: See the &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/docs/building-operators/golang/"&gt;Operator SDK documentation&lt;/a&gt; for more about building Operators with &lt;code&gt;operator-sdk&lt;/code&gt; and Golang.&lt;/p&gt; &lt;h2&gt;Building an Operator bundle image&lt;/h2&gt; &lt;p&gt;Apart from the Operator image, an &lt;em&gt;operator bundle&lt;/em&gt; is an OLM-prescribed format for holding Operator metadata. The metadata contains everything Kubernetes needs to know to use the Operator, including its custom resource definitions (CRDs), required role-based access and control (RBAC) roles and bindings, dependency tree, and more.&lt;/p&gt; &lt;h3&gt;Generate a bundle&lt;/h3&gt; &lt;p&gt;You can use the &lt;code&gt;operator-sdk&lt;/code&gt;-generated Makefile to create a bundle for your Operator:&lt;/p&gt; &lt;pre&gt;$ make bundle IMG=quay.io/username/doo-operator:v0.0.1 &lt;/pre&gt; &lt;p&gt;This command generates an on-disk set of bundle manifests. Here is an example of the directory structure for a generated bundle:&lt;/p&gt; &lt;pre&gt;bundle ├── manifests │   ├── cache.example.com_dooes.yaml │   ├── doo.clusterserviceversion.yaml │   └── doo-metrics-reader_rbac.authorization.k8s.io_v1beta1_clusterrole.yaml ├── metadata │   └── annotations.yaml └── tests     └── scorecard         └── config.yaml &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;make bundle&lt;/code&gt; command also creates a Dockerfile (&lt;code&gt;bundle.Dockerfile&lt;/code&gt;), which is used to build a &lt;em&gt;bundle image&lt;/em&gt;. The bundle image is an &lt;a target="_blank" rel="nofollow" href="https://github.com/opencontainers/image-spec"&gt;Open Container Initiative&lt;/a&gt; (OCI)-compliant image that holds the generated on-disk bundle manifest and metadata files.&lt;/p&gt; &lt;h3&gt;Create and push the bundle image&lt;/h3&gt; &lt;p&gt;In this example, we&amp;#8217;ll name the Operator bundle image as follows:&lt;/p&gt; &lt;pre&gt;quay.io/username/doo-operator-bundle:v0.0.1 &lt;/pre&gt; &lt;p&gt;To create and push the image, run the following Makefile targets:&lt;/p&gt; &lt;pre&gt;$ make bundle-build BUNDLE_IMG=quay.io/username/doo-operator-bundle:v0.0.1 $ make docker-push IMG=quay.io/username/doo-operator-bundle:v0.0.1 &lt;/pre&gt; &lt;h2&gt;Building the Operator index image&lt;/h2&gt; &lt;p&gt;Another OLM concept is the &lt;em&gt;index image&lt;/em&gt;. This container image serves an application programming interface (API), which describes information about your sample Operator. The index image includes information from your bundle image by running &lt;code&gt;opm&lt;/code&gt;, an Operator registry command:&lt;/p&gt; &lt;pre&gt;$ opm index add --bundles quay.io/username/doo-operator-bundle:v0.0.1 --tag quay.io/username/doo-operator-index:v0.0.1 $ podman push quay.io/username/doo-operator-index:v0.0.1 &lt;/pre&gt; &lt;p&gt;The index image holds an &lt;a target="_blank" rel="nofollow" href="https://www.sqlite.org"&gt;SQLite&lt;/a&gt; database with bundle definitions. It also runs a &lt;a target="_blank" rel="nofollow" href="https://grpc.io/docs/what-is-grpc/core-concepts/"&gt;gRPC&lt;/a&gt; service when the image is executed. The gRPC service lets consumers query the SQLite database about the Operators the index contains.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: You can download the &lt;code&gt;opm&lt;/code&gt; command from the Operator Framework&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-registry"&gt;Operator registry&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Running the bundle index image&lt;/h2&gt; &lt;p&gt;At this point, you should have OLM installed on your Kubernetes cluster. OLM is installed by default on OpenShift clusters. You can use Operator SDK&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/docs/cli/operator-sdk_olm_install/"&gt;olm install&lt;/a&gt; command to install OLM on any other Kubernetes cluster manually.&lt;/p&gt; &lt;p&gt;Once you have an index image, deploy it by creating an OLM &lt;code&gt;CatalogSource&lt;/code&gt; resource. For our sample Operator, we create the &lt;code&gt;CatalogSource&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt;$ cat &amp;#60;&amp;#60;EOF | kubectl create -f - kind: CatalogSource metadata:   name: doo-operator   namespace: operators spec:   sourceType: grpc   image: quay.io/username/doo-operator-index:v0.0.1 EOF &lt;/pre&gt; &lt;p&gt;This &lt;code&gt;CatalogSource&lt;/code&gt; is created in an existing namespace, created by OLM, named &lt;code&gt;operators&lt;/code&gt;. On OpenShift clusters, this namespace is called &lt;code&gt;openshift-operators&lt;/code&gt;. When you create the &lt;code&gt;CatalogSource&lt;/code&gt;, it causes the index image to be executed as a pod. You can view it as follows:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators get pod --selector=olm.catalogSource=doo-operator NAME                                                              READY   STATUS      RESTARTS   AGE doo-operator-79x8z                                                1/1     Running     0          136m &lt;/pre&gt; &lt;p&gt;You can look at the pod&amp;#8217;s log to ensure the image is serving the gRPC API:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators logs pod/doo-operator-79x8z time="2020-10-05T13:17:04Z" level=info msg="Keeping server open for infinite seconds" database=/database/index.db port=50051 time="2020-10-05T13:17:04Z" level=info msg="serving registry" database=/database/index.db port=50051 &lt;/pre&gt; &lt;h2&gt;Deploying the Operator&lt;/h2&gt; &lt;p&gt;We use an OLM &lt;em&gt;subscription&lt;/em&gt; resource to trigger a specific Operator deployment. With the following command, we create a &lt;code&gt;Subscription&lt;/code&gt; that triggers the deployment of our sample Operator:&lt;/p&gt; &lt;pre&gt;$ cat &amp;#60;&amp;#60;EOF | kubectl create -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata:   name: doo-subscription   namespace: operators  spec:   channel: alpha   name: doo   source: doo-operator   sourceNamespace: operators EOF &lt;/pre&gt; &lt;p&gt;Notice that the &lt;code&gt;Subscription&lt;/code&gt; is created in the pre-existing &lt;code&gt;operators&lt;/code&gt; namespace so that OLM will create the sample Operator in that same namespace. (Note, again, that on OpenShift clusters, the namespace is called &lt;code&gt;openshift-operators&lt;/code&gt;.)&lt;/p&gt; &lt;h2&gt;Verifying the Operator&lt;/h2&gt; &lt;p&gt;We can use the following commands to verify the sample Operator is running. Let&amp;#8217;s start by verifying the &lt;code&gt;Subscription&lt;/code&gt; has been created:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators get subscription NAME               PACKAGE   SOURCE         CHANNEL doo-subscription   doo       doo-operator   alpha &lt;/pre&gt; &lt;p&gt;Next, verify the operator CSV has successfully deployed:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators get csv NAME         DISPLAY        VERSION   REPLACES   PHASE doo.v0.0.1   doo-operator   0.0.1                Succeeded &lt;/pre&gt; &lt;p&gt;Finally, verify the Operator is running:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators get pod NAME                                      READY   STATUS    RESTARTS   AGE doo-controller-manager-6c4bdf7db6-jcvpn   2/2     Running   0          10m &lt;/pre&gt; &lt;h2&gt;Testing the Operator&lt;/h2&gt; &lt;p&gt;We can test the sample Operator by creating a &lt;code&gt;CustomResource&lt;/code&gt; that the sample Operator is watching.&lt;br /&gt; Create the &lt;code&gt;CustomResource&lt;/code&gt; in the &lt;code&gt;default&lt;/code&gt; namespace as follows:&lt;/p&gt; &lt;pre&gt;$ cat &amp;#60;&amp;#60;EOF | kubectl -n default create -f - {            "apiVersion": "cache.example.com/v1",            "kind": "Doo",            "metadata": {              "name": "doo-sample"            },            "spec": {              "foo": "bar"            }          }  EOF &lt;/pre&gt; &lt;p&gt;Your sample Operator should respond to the creation of the &lt;code&gt;CustomResource&lt;/code&gt; by checking the sample Operator log:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators logs pod/doo-controller-manager-6c4bdf7db6-jcvpn -c manager 2020-10-05T13:29:52.175Z DEBUG controller Successfully Reconciled{"reconcilerGroup": "cache.example.com", "reconcilerKind": "Doo", "controller": "doo", "name": "doo-sample", "namespace": "default"} &lt;/pre&gt; &lt;h2&gt;Create a unique namespace and OperatorGroup&lt;/h2&gt; &lt;p&gt;Examples so far used namespaces that were pre-created when you installed OLM. In some cases, you might want to isolate your Operator deployments into a namespace that you create. For this, you will need to create a unique namespace and &lt;code&gt;OperatorGroup&lt;/code&gt;. My namespace for this example is &lt;code&gt;jeff-operators&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ kubectl create namespace jeff-operators $ cat &amp;#60;&amp;#60;EOF | kubectl create -f - apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata:   name: jeff-operators   namespace: jeff-operators status:   lastUpdated: "2020-10-07T13:44:54Z"   namespaces:   - "" EOF &lt;/pre&gt; &lt;p&gt;Note that you create the unique namespace &lt;em&gt;before&lt;/em&gt; creating your &lt;code&gt;CatalogSource&lt;/code&gt; and subscription. You will need to create these components in the namespace that contains your &lt;code&gt;OperatorGroup&lt;/code&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: For more about &lt;code&gt;OperatorGroup&lt;/code&gt;s, see &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-lifecycle-manager/blob/master/doc/design/operatorgroups.md"&gt;Operator Multitenancy with OperatorGroups&lt;/a&gt; in the OLM GitHub repository.&lt;/p&gt; &lt;h2&gt;OLM bundle automation in Operator SDK&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;operator-sdk&lt;/code&gt; includes a new &lt;code&gt;run bundle&lt;/code&gt; command that uses a temporary bundle index image for many of the steps described in this article. The &lt;code&gt;run bundle&lt;/code&gt; command will be useful for developers needing to test their Operators using the OLM bundle architecture.  Here&amp;#8217;s an example of the command:&lt;/p&gt; &lt;pre&gt;$ operator-sdk run bundle quay.io/username/doo-operator-bundle:v0.0.1 &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The Operator Lifecycle Manager&amp;#8217;s bundle architecture is an advanced mechanism for describing, publishing, and deploying Operators on Kubernetes clusters. This article introduced you to using OLM&amp;#8217;s bundle deployment architecture and the Operator SDK to deploy a Kubernetes Operator.&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;See the following resources to learn more about OLM and the Operator Framework:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Visit the &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-lifecycle-manager"&gt;OLM GitHub repository&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://olm.operatorframework.io"&gt;OLM homepage&lt;/a&gt; for more about using the Operator Lifecycle Manager to install, manage, and upgrade Operators and their dependencies in a Kubernetes cluster.&lt;/li&gt; &lt;li&gt;Learn more about &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-lifecycle-manager/blob/master/doc/design/operatorgroups.md"&gt;Operator multitenancy with OperatorGroups&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;See the &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/docs/building-operators/golang/"&gt;Guide to building a Golang based Operator using Operator SDK&lt;/a&gt; for a quickstart for creating Go-based Operators and more.&lt;/li&gt; &lt;li&gt;Find out more about &lt;a target="_blank" rel="nofollow" href="https://www.sqlite.org/index.html"&gt;SQLite&lt;/a&gt; and the &lt;a target="_blank" rel="nofollow" href="https://sqlitebrowser.org/"&gt;Database Browser for SQLite&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Get started with &lt;a target="_blank" rel="nofollow" href="https://grpc.io/"&gt;gRPC&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://github.com/fullstorydev/grpcurl"&gt;using the grpcurl command-line tool&lt;/a&gt; to interact with gRPC servers.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;Thanks to Red Hat engineers Eric Stroczynski and Jesus Rodriguez for reviewing this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#038;title=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" data-a2a-url="https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/" data-a2a-title="Deploying Kubernetes Operators with Operator Lifecycle Manager bundles"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/"&gt;Deploying Kubernetes Operators with Operator Lifecycle Manager bundles&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Fz4zpPjv0vk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article shows an example of using the Operator Lifecycle Manager (OLM) bundle deployment architecture to deploy a Red Hat OpenShift or other Kubernetes Operator. You will learn how to use OLM and the Operator SDK (both components of the Kubernetes Operator Framework) together to deploy an Operator. About the example I tested the Operator Lifecycle [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/"&gt;Deploying Kubernetes Operators with Operator Lifecycle Manager bundles&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">798747</post-id><dc:creator>Jeff McCormick</dc:creator><dc:date>2021-02-08T08:00:18Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/</feedburner:origLink></entry><entry><title type="html">The After Open Source Era Has Started</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Y3vVQPN_GKk/the-after-open-source-era-has-started.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2021/02/the-after-open-source-era-has-started.html</id><updated>2021-02-07T08:32:00Z</updated><content type="html">Open source is the current norm for developer collaboration and customer adoption in software. It is the foundation that enabled unicorns and cloud providers to build their services from the ground up. But that wasn’t always the case with open source, and it is changing and evolving again. Open Source Eras and relative adoption trend lines In this post, I will look at open source evolution broadly, try to analyze what are some of the triggers and enablers for the change, and where it might be heading next. Let’s start with the main open software development eras by summarizing the main trends and then focus on the big picture with an attempt to predict the future. FREE SOFTWARE (1980) The term “free software” is attributed to Richard Stallman around the 1980s for using it for the . During these early days of computing, Richard started the GNU project in an effort to cultivate collaboration among the early hacker community and create a freedom-respecting operating system. He campaigns for software to be distributed in a manner such that its users receive the freedoms to use, study, distribute, and modify that software. This era set the origins of open source and more importantly the free software licenses (such as GPL) that flourish later. At the time, the main software creators in the open were the individual hackers and in their view of the world, the software had to be free as speech and remain so. Free software grew because personal computers became more widely available to these hackers and they used CDs, floppy disks, and the early internet to distribute software and spread their ideology. In this pre-internet era, manual distributions of software, supporting documentation, consulting services (installation, development), were some of the popular monetization methods. OPEN SOURCE SOFTWARE (2000) The term "open source" was used by a group of people from the free-software movement around 2000. The motivation for this new term was to free itself from the ideological and confrontational connotations of the term "free software" and make it more appealing for the business world. The supporters of the open source movement stress the subtle difference from free software where free software requires any changes to be submitted to the original maker for redistribution, and any derivative software must also be distributed as free software. This new term set the beginning of a new movement and the forming of to educate and advance open source culture. The open source movement allowed smaller companies to play a more significant role in the software economy by giving them access to the software needed to compete in the global market. Before that, it was the larger corporations, the producers of the networks and hardware who had the power. Open source sparked from the early hackers community but grew rapidly into open source businesses, enabled by software foundations, the internet, and the wider adoption of open source by companies of all sizes. The primary monetization mechanism for the open source software is through support and the open core models where additional accompanying value is created around the core open source project. While this open core (enabled by permissive licenses such as MIT, Apache) allows everybody to benefit from it, it is also its Achilles' heel as we will see next. SHARED SOURCE SOFTWARE (2020) Open source licenses give more freedom to the users, but they don’t give many advantages to the producers of the software. Many small projects with a handful of maintainers create huge economic value which ends up captured by other companies with better operational capabilities to monetize. This leads the maintainers of these projects to remain below the poverty line. Other companies hire open source maintainers as full-time employers and bet their company existence and brand into the success of their open source project. Yet they got disrupted and threatened by even larger hyperscale SaaS providers who have the scale to capture the economical value more efficiently and faster from the same projects. This new economic reality started forcing individual maintainers and small companies to move their software away from business-friendly open source to other free software inspired derivative licenses and pursue dual-licensing models. This new family of licenses is not proprietary, but they don’t fit the open source definition either as they protect the trademark owner from the competition by discriminating against certain ways of software distributions such as SaaS. This transition of new and existing open source projects to non-open source licenses indicates the start of a new era. Keeping the source partially open is primarily for marketing and user adoption purposes rather than collaborative development and keeping software useful for everybody. This shared source software era is triggered by the existential threat of not being able to offer the software in a way demanded by consumers (as a SaaS) and efficiently capture economical value by the creators whether they are individual contributors or large companies with an open source business model. Open source software eras and main characteristics Protected by these new licenses, the enablers for the modern-day independent hackers are the powerful online services that allow them to offer good quality software through globally available automation tools based on git, build tools, software scanning, and distribution services, etc. These hackers can build enough critical mass of supporters through social media and are able to capture economical value through services such as Github sponsors, Patreon, Tidelift, and . The other group, the disrupted open source companies are transitioning to the SaaS based distribution of software as vertical cloud services on top of the hybrid cloud infrastructure to compete with cloud providers. This allows the creators of the software to offer their service on multiple clouds and at the same time align with the way users prefer to consume software, which is as a service. WHAT WILL SOFTWARE AFTER OPEN SOURCE LOOK LIKE? The start of a new trend doesn’t indicate the end of the existing eras, but a new addition to the mix. Free and open source software will continue growing at a huge pace. At the same time, I believe we will see an acceleration of the trend towards the so-called shared source and source available licenses too. This will double down on the dual-licensing of smaller library projects by individual developers and the SaaS-based distribution of bigger projects. The open core and open source models will remain here, but the open core of the projects will get smaller and smaller, practically useless for the competitors. We will see projects starting as open source during bootstrapping and initial adoption phases, and then transition to source available licenses when threatened by more operationally mature competitors. Unfortunately, this initial phase of uncertainty and adaptation in the shared source era will limit collaboration among competitors and demonstrate the importance of open governance and open funding through neutral software foundations or decentralized technologies. Then we will see cycles repeating and independent hackers flourish again, innovating as in the free software era. But this time they will be better equipped with better infrastructure to support their livelihood as independent small businesses of one. They will start projects in the open to scratch their itch, but quickly turn them into businesses or let them die. They will be less ideological, and more practical. These independent hackers will not need to be part of the traditional horizontal software companies that bundle engineering, marketing, sales, support, education, etc to be successful in the software business. Instead, they will be able to consume unbundled vertical online services and deliver enterprise-grade software. We will see a rise in the tools and platforms that offer reliable project governance without joining a foundation or consortium. Independent software builders can use decentralized , their projects, and customize the through on-chain community voting. The economical and governance aspects of the projects will be merged with the source code and licenses into a holistic entity enabled by blockchain technology and create opportunities for individual hackers to create million-dollar companies. The infrastructure for independent techies will not be only for the software builders but for the whole ecosystem. Creating software is not enough, it has to go through the full pipeline of budgeting, building, marketing, hosting, sales, support in order to grow and remain sustainable. Speculators will put money into project tokens to help bootstrap projects and gain returns. Developers will build. Indies will create niche services complementing larger projects. Subject matter experts will provide consulting services and online training, and bounty hackers will hunt for ad-hoc work. Sometimes all of it will be driven by a single person, and sometimes a whole decentralized ecosystem forming around a project without the dominance of a central business entity. This will take a generation of software builders... CONCLUSION At the beginning of the open source era, Eric S. Raymond described a decentralized software development process called . This era proved that the bazaar is the superior software development model. But at the same time, this era also showed us the limitations and the narrow mindedness of this model when it is not accompanied by a . The next era will improve on the same decentralized development principles by incorporating decentralized monetization and governance too. This will take us the full cycle of Decentralized and Sustainable Open Software nirvana. If you like my explorations of opensource, blockchain, monetization, sing up to my or follow me on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Y3vVQPN_GKk" height="1" width="1" alt=""/&gt;</content><dc:creator>Unknown</dc:creator><feedburner:origLink>http://www.ofbizian.com/2021/02/the-after-open-source-era-has-started.html</feedburner:origLink></entry><entry><title type="html">Eclipse Vert.x 4.0.2 released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-fYwOHvjKE4/eclipse-vert-x-4-0-2" /><author><name>Julien Viet</name></author><id>https://vertx.io/eclipse-vert-x-4-0-2</id><updated>2021-02-05T00:00:00Z</updated><content type="html">Eclipse Vert.x version 4.0.2 has just been released. It fixes quite a few bugs that have been reported by the community.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-fYwOHvjKE4" height="1" width="1" alt=""/&gt;</content><dc:creator>Julien Viet</dc:creator><feedburner:origLink>https://vertx.io/eclipse-vert-x-4-0-2</feedburner:origLink></entry><entry><title>A guide for using CentOS Project code</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/p39_GzFB7Us/" /><category term="Linux" /><category term="Open source" /><category term="CentOS" /><category term="CentOS Stream" /><author><name>Brian Exelbierd</name></author><id>https://developers.redhat.com/blog/?p=866107</id><updated>2021-02-03T17:32:53Z</updated><published>2021-02-03T17:32:53Z</published><content type="html">&lt;p&gt;Many people have approached us asking about how we will publish the CentOS sources and if we are making changes because of &lt;a target="_blank" rel="nofollow" href="https://blog.centos.org/2020/12/future-is-centos-stream/"&gt;the announcements&lt;/a&gt; on 8 December 2020 that we are focusing on CentOS Stream. In short, we are not making any changes to this process.&lt;/p&gt; &lt;p&gt;The CentOS sources will still be published to git.centos.org in repositories that contain dist-git style sources. If you are looking for public access to the code, this will be the place to go.&lt;/p&gt; &lt;p&gt;If you’re considering using this code in your own project &amp;#8211; especially if that project has the goal of producing a Linux distribution &amp;#8211; we’ve put together some guidance to help you comply with the Red Hat services agreements and trademark guidelines. This guidance is not exhaustive.&lt;/p&gt; &lt;p&gt;In the spirit of community collaboration, we offer a list of do’s and don’ts below.&lt;/p&gt; &lt;h1&gt;Do&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Get your source code from upstream or git.centos.org and follow the &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/about/trademark-guidelines-and-policies"&gt;Red Hat trademark guidelines&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Clearly describe your distribution as something you made, not Red Hat.  You may wish to say you started with source from a specific location, such as “modified and built from source code taken from git.centos.org.”&lt;/li&gt; &lt;li&gt;Prominently include the following disclaimer when publishing or promoting your distribution: “Red Hat and CentOS are trademarks or registered trademarks of Red Hat, Inc. or its subsidiaries in the United States and other countries. We are not affiliated with, endorsed by or sponsored by Red Hat or the CentOS Project.”&lt;/li&gt; &lt;li&gt;Comply with the GPL and all the other open source licenses applicable to your build.&lt;/li&gt; &lt;li&gt;If you have an agreement with Red Hat, such as being a member of the Red Hat Developer program or working for a Red Hat customer or partner, review the terms of the agreement so you know your obligations  (&lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/about/agreements"&gt;https://www.redhat.com/en/about/agreements&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/wapps/tnc/viewterms/72ce03fd-1564-41f3-9707-a09747625585?extIdCarryOver=true&amp;#38;sc_cid=701f2000001Css0AAC"&gt;individual developer program&lt;/a&gt;, respectively).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h1&gt;Don’t&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Use Red Hat Subscription Services to create or support your project.&lt;/li&gt; &lt;li&gt;Use any Red Hat trademarks, including the Red Hat logo, in the project,  your distribution, or in your promotion and marketing of the project, other than as permitted under &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/about/trademark-guidelines-and-policies"&gt;Red Hat’s trademark guidelines&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#038;title=A%20guide%20for%20using%20CentOS%20Project%20code" data-a2a-url="https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/" data-a2a-title="A guide for using CentOS Project code"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/"&gt;A guide for using CentOS Project code&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/p39_GzFB7Us" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Many people have approached us asking about how we will publish the CentOS sources and if we are making changes because of the announcements on 8 December 2020 that we are focusing on CentOS Stream. In short, we are not making any changes to this process. The CentOS sources will still be published to git.centos.org [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/"&gt;A guide for using CentOS Project code&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">866107</post-id><dc:creator>Brian Exelbierd</dc:creator><dc:date>2021-02-03T17:32:53Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/</feedburner:origLink></entry><entry><title>Deliver your applications to edge and IoT devices in rootless containers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/yzTCTOw-I0A/" /><category term="Automation" /><category term="CI/CD" /><category term="Containers" /><category term="Internet of Things" /><category term="Kubernetes" /><category term="Ansible" /><category term="edge applications" /><category term="iot edge" /><category term="Podman" /><author><name>Ilkka Tengvall</name></author><id>https://developers.redhat.com/blog/?p=851907</id><updated>2021-02-03T08:00:37Z</updated><published>2021-02-03T08:00:37Z</published><content type="html">&lt;p&gt;Applications are often developed, tested, and delivered in &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; is a great platform for that purpose. Sometimes, however, the target machine is much smaller than a &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; cluster. It might be an embedded server, industry PC hardware, or a single server.&lt;br /&gt; &lt;img class=" alignright wp-image-852007 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2021/01/systemd-podman-ansible.png" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/systemd-podman-ansible.png" alt="Image: Systemd + Podman + Ansible." width="291" height="69" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/systemd-podman-ansible.png 672w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/systemd-podman-ansible-300x71.png 300w" sizes="(max-width: 291px) 100vw, 291px" /&gt;&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s say the target machine was a &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) &lt;a href="https://developers.redhat.com/topics/edge-computing"&gt;edge server&lt;/a&gt;? How would you automate your container to run in that environment? What if you had &lt;i&gt;thousands of such devices&lt;/i&gt;? In that case, you would want a fully automated rootless container for security. But how do you automate rootless containers?&lt;/p&gt; &lt;p&gt;In this article, you&amp;#8217;ll learn how to use systemd, &lt;a href="https://developers.redhat.com/articles/podman-next-generation-linux-container-tools"&gt;Podman&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Red Hat Ansible Automation&lt;/a&gt; to automate and push software as containers to small-scale edge and &lt;a href="https://developers.redhat.com/blog/category/iot/"&gt;Internet-of-Things&lt;/a&gt; (IoT) gateway devices.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: While I have not included &lt;a target="_blank" rel="nofollow" href="https://www.ansible.com/products/tower"&gt;Red Hat Ansible Tower&lt;/a&gt; in the demonstration, integrating it would be the next logical next step.&lt;/p&gt; &lt;h2&gt;Why rootless containers?&lt;/h2&gt; &lt;p&gt;Why should you use &lt;a href="https://developers.redhat.com/blog/2020/09/25/rootless-containers-with-podman-the-basics/"&gt;rootless containers&lt;/a&gt; to deliver applications to edge and IoT boxes? Well, it&amp;#8217;s another layer of security. Even if an evil blackhat manages to break into your container, find a security hole, and punch through your Security-Enhanced Linux (SELinux) module, the rootless container ensures they won&amp;#8217;t have privileges in the system.&lt;/p&gt; &lt;p&gt;As a developer, you also don’t necessarily need root privileges in the target device. Your team could deliver the application to end devices as containers, while only admins have the privileges to manage the boxes.&lt;/p&gt; &lt;h2&gt;Set up the development environment&lt;/h2&gt; &lt;p&gt;I’ve previously written about &lt;a target="_blank" rel="nofollow" href="https://redhatnordicssa.github.io/ansible-podman-containers-1"&gt;automating Podman containers with Ansible&lt;/a&gt;, but I&amp;#8217;ve only recently added the rootless option to my Ansible role. We’ll use &lt;a target="_blank" rel="nofollow" href="https://galaxy.ansible.com/ikke_t/podman_container_systemd"&gt;the updated Ansible role&lt;/a&gt; and an &lt;a target="_blank" rel="nofollow" href="https://github.com/ansible-collections/community.grafana"&gt;Ansible module for Grafana&lt;/a&gt; for this demonstration.&lt;/p&gt; &lt;p&gt;We&amp;#8217;ll set up Grafana with a dummy dashboard and test users for an RHEL edge server to get started. I have tested the example also on a Fedora IoT distribution and a standard RHEL server.&lt;/p&gt; &lt;p&gt;Our end goal is to create persistent containers using systemd, Podman, and Ansible Tower, where the containers have user-only privileges. In this case, systemd manages the user processes, but any Docker container would work the same. Figure 1 shows how these components would work together.&lt;/p&gt; &lt;div id="attachment_851967" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user.png"&gt;&lt;img aria-describedby="caption-attachment-851967" class=" alignright wp-image-851967 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-1024x640.png" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-1024x640.png" alt="A flow diagram for the example." width="640" height="400" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-1024x640.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-300x188.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-768x480.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851967" class="wp-caption-text"&gt;Figure 1: Creating persistent containers with systemd, Podman, and Ansible Tower.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the next sections, we&amp;#8217;ll set up and configure this automation.&lt;/p&gt; &lt;h2&gt;Systemd changes in Ansible&lt;/h2&gt; &lt;p&gt;First, let&amp;#8217;s look at what needs to change to make the &lt;a target="_blank" rel="nofollow" href="https://galaxy.ansible.com/ikke_t/podman_container_systemd"&gt;podman_container_systemd&lt;/a&gt; role work in user mode. We&amp;#8217;ll also look at the changes needed for Fedora CoreOS and similar servers that are intended to run only containers.&lt;/p&gt; &lt;h3&gt;User systemd services&lt;/h3&gt; &lt;p&gt;The first thing we&amp;#8217;ll do is move all of the service files into the user&amp;#8217;s home directory instead of the &lt;code&gt;/etc/systemd/system&lt;/code&gt; or &lt;code&gt;/usr/lib/systemd/system&lt;/code&gt; system config directories. We could technically use the &lt;code&gt;/usr/lib/systemd/user&lt;/code&gt;directory, but we want the service files to be private to the user. This way, anyone on the application team can modify them as a regular user if needed.&lt;/p&gt; &lt;p&gt;Here’s the &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L12"&gt;configuration code for this step&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;   - name: set systemd dir if user is not root      set_fact:        service_files_dir: "{{ user_info.home }}/.config/systemd/user"         systemd_scope: user      changed_when: false     - name: ensure systemd files directory exists if user not root      file:         path: "{{ service_files_dir }}"        state: directory        owner: "{{ container_run_as_user }}"        group: "{{ container_run_as_group }}" &lt;/pre&gt; &lt;h3&gt;Configure a persistent D-BUS session&lt;/h3&gt; &lt;p&gt;The biggest hurdle for me was understanding how a service user gets a &lt;a target="_blank" rel="nofollow" href="https://www.freedesktop.org/wiki/Software/dbus/"&gt;D-BUS session&lt;/a&gt;, which remains available over boots even if the user never logs in. Additionally, systemd must be able to control the user&amp;#8217;s Podman session. We can handle these requirements by setting up a &lt;a target="_blank" rel="nofollow" href="https://www.freedesktop.org/software/systemd/man/loginctl.html"&gt;lingering session&lt;/a&gt; for the user, which activates &lt;code&gt;dbus&lt;/code&gt; for a given user at boot. Here&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L159"&gt;how to set up the lingering session&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; - name: Check if user is lingering    stat:      path: "/var/lib/systemd/linger/{{ container_run_as_user }}"    register: user_lingering    when: container_run_as_user != "root"   - name: Enable lingering is needed    command: "loginctl enable-linger {{ container_run_as_user }}"    when:      - container_run_as_user != "root"      - not user_lingering.stat.exists &lt;/pre&gt; &lt;p&gt;Next, we need to ensure that the systemd commands are &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L33"&gt;executed in user scope&lt;/a&gt;. Because we don’t log in as the target user, but as a privileged Ansible user, we will set an environment variable for &lt;code&gt;xdg_runtime_dir&lt;/code&gt;. We can use this variable to find the user’s lingering &lt;code&gt;dbus&lt;/code&gt; session later. Here is how to &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L33"&gt;set systemd&amp;#8217;s scope to user&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;- name: set systemd runtime dir  set_fact:    xdg_runtime_dir: "/run/user/{{ container_run_as_uid.stdout }}"  changed_when: false - name: set systemd scope to system if needed  set_fact:    systemd_scope: system    service_files_dir: '/etc/systemd/system'    xdg_runtime_dir: "/run/user/{{ container_run_as_uid.stdout }}"  when: container_run_as_user == "root"  changed_when: false &lt;/pre&gt; &lt;h2&gt;Set the default target&lt;/h2&gt; &lt;p&gt;We also need to change the systemd session file to the default target when it&amp;#8217;s run in rootless. Here&amp;#8217;s the &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/templates/systemd-service-single.j2#L26"&gt;configuration for the default target&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;[Install] {% if container_run_as_user == 'root' %} WantedBy=multi-user.target {% endif %} {% if container_run_as_user != 'root' %} WantedBy=default.target {% endif %} &lt;/pre&gt; &lt;h3&gt;User systemd commands&lt;/h3&gt; &lt;p&gt;We&amp;#8217;ve set all the required variables. Next, we need to &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/handlers/main.yml#L12"&gt;tell Ansible to use the D-BUS session&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;- name: start service  become: true  become_user: "{{ container_run_as_user }}"  environment:    XDG_RUNTIME_DIR: "{{ xdg_runtime_dir }}"  systemd:    name: "{{ service_name }}"    scope: "{{ systemd_scope }}"    state: started &lt;/pre&gt; &lt;p&gt;Note that we switch to a given user and set the runtime directory to catch the D-BUS. Also, the scope is set to &lt;code&gt;user&lt;/code&gt; instead of &lt;code&gt;system&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;RPM-OSTREE package handling&lt;/h3&gt; &lt;p&gt;For my own purposes, I want to run these containers in minimal, Fedora CoreOS-based machines. Strangely, Ansible doesn’t have a proper package module for this setup. So, I used the following &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L227"&gt;workaround for checking and installing packages&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;- name: ensure firewalld is installed (on fedora-iot)    tags: firewall    command: &amp;#62;-      rpm-ostree install --idempotent --unchanged-exit-77      --allow-inactive firewalld    register: ostree    failed_when: not ( ostree.rc == 77 or ostree.rc == 0 )    changed_when: ostree.rc != 77    when: ansible_pkg_mgr == "atomic_container"  - name: reboot if new stuff was installed    reboot:      reboot_timeout: 300    when:      - ansible_pkg_mgr == "atomic_container"      - ostree.rc != 77 &lt;/pre&gt; &lt;p&gt;You might not want to install anything there, but this configuration handles the required reboot if you do. It made sense for using Fedora CoreOS in an IoT system.&lt;/p&gt; &lt;p&gt;At this point, we are pretty much done with the changes.&lt;/p&gt; &lt;h2&gt;Try it out&lt;/h2&gt; &lt;p&gt;In case you want to try this yourself (and why wouldn’t you?), I will share the commands to run this example in your own environment. I used RHEL 8 on my laptop and an RHEL edge server as the target virtual machine. If you don&amp;#8217;t have access to RHEL edge, you can also use Feroda-IoT as the target.&lt;/p&gt; &lt;p&gt;I like to keep everything related to tasks in one directory, including the required collections and roles. I&amp;#8217;ve set all of this up, including the requirements files, in the example project repository. All you need to do is get it:&lt;/p&gt; &lt;pre&gt;sudo dnf install ansible git clone https://github.com/ikke-t/ansible-podman-sample.git cd ansible-podman-sample &lt;/pre&gt; &lt;p&gt;Then, install the role and collection dependencies:&lt;/p&gt; &lt;pre&gt;ansible-galaxy collection install -r collections/requirements.yml -p collections ansible-galaxy role install -r roles/requirements.yml -p roles &lt;/pre&gt; &lt;p&gt;And run the playbook:&lt;/p&gt; &lt;pre&gt;ln -s roles/ikke_t.grafana_podman/tests/test.yml run-container-grafana-podman.yml ansible-playbook -i edge, -u cloud-user -b \  -e container_state=running \  -e ansible_pkg_mgr=atomic_container \  run-container-grafana-podman.yml &lt;/pre&gt; &lt;p&gt;You will need to change the following settings for your system:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;You only need the &lt;code&gt;ansible_pkg_mgr&lt;/code&gt; setting if &lt;a target="_blank" rel="nofollow" href="https://github.com/ansible/ansible/issues/73084"&gt;the target is an RHEL edge server&lt;/a&gt;; otherwise, you can remove this line.&lt;/li&gt; &lt;li&gt;&lt;code&gt;edge&lt;/code&gt; is my VM server&amp;#8217;s SSH address.&lt;/li&gt; &lt;li&gt;&lt;code&gt;cloud-user&lt;/code&gt; is the &lt;code&gt;sudo&lt;/code&gt;-privileged Ansible user in the target VM.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let it run for a minute, and &amp;#8230; drumroll &amp;#8230; &lt;em&gt;ta-dah!&lt;/em&gt; As shown in Figure 2, we have our Grafana dashboard running in a user session as a container (http://your_vm:3000).&lt;/p&gt; &lt;div id="attachment_851937" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-851937" class=" alignright wp-image-851937 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard.png" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard-300x177.png" alt="The Grafana dashboard running in a user session." width="600" height="355" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard-300x177.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard-768x454.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard.png 827w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-851937" class="wp-caption-text"&gt;Figure 2: A simple streaming example in the Grafana dashboard.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 3 shows the test users pushed over the API using the Ansible Grafana collection.&lt;/p&gt; &lt;div id="attachment_851947" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-851947" class=" alignright wp-image-851947 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users.png" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users.png" alt="The Grafana dashboard showing an admin, test-admin, and test-user and their roles." width="600" height="355" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users.png 827w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users-300x177.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users-768x454.png 768w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-851947" class="wp-caption-text"&gt;Figure 3: Admin and test users in the Grafana dashboard.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Debugging locally in the target&lt;/h2&gt; &lt;p&gt;We are running the containers as a user, and this Ansible role places them under the user context of systemd.  To use systemd as a given user,  you need to set up a D-BUS-related environment variable. However, the user does not have login credentials, so you need to switch manually to the user using &lt;code&gt;su&lt;/code&gt;. (Note that &lt;code&gt;sudo&lt;/code&gt; won&amp;#8217;t work because the original user ID would show your &lt;code&gt;ssh&lt;/code&gt; user ID.)&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s the command to switch manually to the user:&lt;/p&gt; &lt;pre&gt;su - root su - grafana export XDG_RUNTIME_DIR=/run/user/$UID &lt;/pre&gt; &lt;p&gt;After setting &lt;code&gt;XDG_RUNTIME_DIR&lt;/code&gt; you will be able to use the &lt;code&gt;systemd --user&lt;/code&gt; or &lt;code&gt;journalctl --user&lt;/code&gt; commands to investigate your systemd services set for the container:&lt;/p&gt; &lt;pre&gt;[cloud-user@edge ~]$ su - Password: Last login: Thu Dec 31 13:03:43 EET 2020 on pts/2 [root@edge ~]# su - grafana Last login: Thu Dec 31 13:04:41 EET 2020 on pts/1 (failed reverse-i-search)`export': ^C [grafana@edge ~]$ export XDG_RUNTIME_DIR=/run/user/$UID [grafana@edge ~]$ [grafana@edge ~]$ systemctl --user status grafana-container-pod-grafana.service grafana-container-pod-grafana.service - grafana Podman Container   Loaded: loaded (/var/home/grafana/.config/systemd/user/grafana-container-pod-grafana.service; enabled; ve&amp;#62;   Active: active (running) since Thu 2020-12-31 13:06:35 EET; 29min ago  Process: 1122 ExecStartPre=/usr/bin/rm -f /tmp/grafana-container-pod-grafana.service-pid /tmp/grafana-cont&amp;#62; Main PID: 1126 (podman)   CGroup: /user.slice/user-1002.slice/user@1002.service/grafana-container-pod-grafana.service           ├─1126 /usr/bin/podman run --name grafana --rm -p 3000:3000/tcp -e GF_INSTALL_PLUGINS=flant-statu&amp;#62;           ├─1158 /usr/bin/podman run --name grafana --rm -p 3000:3000/tcp -e GF_INSTALL_PLUGINS=flant-statu&amp;#62;           ├─1167 /usr/bin/podman           ├─1200 /usr/bin/slirp4netns --disable-host-loopback --mtu 65520 --enable-sandbox --enable-seccomp&amp;#62;           ├─1206 /usr/bin/fuse-overlayfs -o lowerdir=/var/home/grafana/.local/share/containers/storage/over&amp;#62;           ├─1214 containers-rootlessport           ├─1227 containers-rootlessport-child           ├─1240 /usr/bin/conmon --api-version 1 -c 2675941bf4743ff26860ff2e84ceaaae78f2fcfbe3fef218e0cfee9&amp;#62;           └─2675941bf4743ff26860ff2e84ceaaae78f2fcfbe3fef218e0cfee914aa96b37             └─1251 grafana-server --homepath=/usr/share/grafana --config=/etc/grafana/grafana.ini --packagi&amp;#62; [grafana@edge ~]$ podman ps CONTAINER ID  IMAGE                             COMMAND  CREATED         STATUS             PORTS                   NAMES 2675941bf474  docker.io/grafana/grafana:latest           29 minutes ago  Up 29 minutes ago  0.0.0.0:3000-&amp;#62;3000/tcp  grafana&lt;/pre&gt; &lt;h2&gt;Cleanup (nuke it)&lt;/h2&gt; &lt;p&gt;You&amp;#8217;ve seen how automating rootless Podman containers using Ansible works; now it’s time to clean it all up. Beware that the “&lt;code&gt;nuke=true&lt;/code&gt;” option removes both the Grafana user and the data. Before using this option, make sure you&amp;#8217;ve stored any data you don&amp;#8217;t want to lose. Note, again, that you need to remove the &lt;code&gt;pkg_mgr&lt;/code&gt; if you are not working on an RHEL edge target:&lt;/p&gt; &lt;pre&gt;ansible-playbook -i edge, -u cloud-user -b \  -e container_state=absent \  -e ansible_pkg_mgr=atomic_container \  -e nuke=true \   run-container-grafana-podman.yml &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Podman and systemd work well for running containers in small setups where Kubernetes would be overkill. Ansible is a robust way to create such a setup. Sometimes, as I&amp;#8217;ve shown here, you don’t even need backups because the target is super easy for Ansible to create from scratch, including the application installation and configurations. It also doesn&amp;#8217;t matter if you have one or thousands of machines at the edge; the setup is basically the same. Remember how we configured Grafana over the API and config file? Consider which is better for your application.&lt;/p&gt; &lt;p&gt;By the way, how about updating the application at the edge? In my example, I set up a Podman container tag to periodically poll for new versions of the container. If you &lt;a target="_blank" rel="nofollow" href="http://docs.podman.io/en/latest/markdown/podman-auto-update.1.html"&gt;enable that service&lt;/a&gt;, you only need to push a new version of the container to the registry at the end of a successful &lt;a href="https://developers.redhat.com/courses/middleware/openshift-pipelines"&gt;CI/CD pipeline in Red Hat OpenShift&lt;/a&gt;. Happy containerizing!&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;See the following to learn more about Podman and systemd:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The Podman documentation includes the &lt;a target="_blank" rel="nofollow" href="http://docs.podman.io/en/latest/markdown/podman-generate-systemd.1.html#:~:text=DESCRIPTION,units%20on%20the%20remote%20system."&gt;podman-generate-systemd&lt;/a&gt; man page.&lt;/li&gt; &lt;li&gt;Learn more about &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/sysadmin/podman-shareable-systemd-services"&gt;running containers with Podman and shareable systemd services&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Learn about &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/sysadmin/improved-systemd-podman"&gt;improved integration with systemd&lt;/a&gt; in Podman 2.0.&lt;/li&gt; &lt;li&gt;Use the &lt;a target="_blank" rel="nofollow" href="http://docs.podman.io/en/latest/markdown/podman-auto-update.1.html"&gt;podman-auto-update&lt;/a&gt; command to auto-update containers according to their auto-update policy.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#038;title=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" data-a2a-url="https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/" data-a2a-title="Deliver your applications to edge and IoT devices in rootless containers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/"&gt;Deliver your applications to edge and IoT devices in rootless containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/yzTCTOw-I0A" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Applications are often developed, tested, and delivered in containers, and Red Hat OpenShift is a great platform for that purpose. Sometimes, however, the target machine is much smaller than a Kubernetes cluster. It might be an embedded server, industry PC hardware, or a single server. Let&amp;#8217;s say the target machine was a Red Hat Enterprise [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/"&gt;Deliver your applications to edge and IoT devices in rootless containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">851907</post-id><dc:creator>Ilkka Tengvall</dc:creator><dc:date>2021-02-03T08:00:37Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/</feedburner:origLink></entry><entry><title>Using Node.js? The OpenJS Foundation would like to hear your feedback</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FTSEem2GmoI/" /><category term="Node.js" /><category term="node.js survey" /><category term="OpenJS" /><author><name>Bethany Griggs</name></author><id>https://developers.redhat.com/blog/?p=865017</id><updated>2021-02-03T08:00:25Z</updated><published>2021-02-03T08:00:25Z</published><content type="html">&lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://www.surveymonkey.com/r/7BYTZMS"&gt;2021 Node.js User Survey&lt;/a&gt; is now open.&lt;/p&gt; &lt;p&gt;Node.js is an Impact Project under the &lt;a target="_blank" rel="nofollow" href="https://openjsf.org/"&gt;OpenJS Foundation&lt;/a&gt;. The aim of the 2021 Node.js User Survey is to learn who is using Node.js, and how it is being used. It’s also an opportunity for Node.js users to share any feedback with the project. The survey should take around 20 minutes, and the results are anonymized.&lt;/p&gt; &lt;p&gt;You can check out some of the previous year&amp;#8217;s survey results:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://nodejs.org/en/user-survey-report/"&gt;2018 Node.js User Survey Report&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/nodejs.org/blob/206109d457ea0af0cad9c469364bab0be6375d0e/static/documents/casestudies/Nodejs_2017_User_Survey_Exec_Summary.pdf"&gt;2017 Node.js Survey Executive Summary&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://nodejs.org/static/documents/2016-survey-report.pdf"&gt;2016 User Survey Report&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Participating in the survey will help the OpenJS Foundation and Node.js project shape the future of the project around our users. If you’re interested in the future of Node.js, there’s recently been a “Next 10” effort kicked off that is working to define the strategic directions for the next 10 years of Node.js. You can follow the progress (or participate) in this effort at &lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/next-10"&gt;https://github.com/nodejs/next-10&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Also of interest, check out the recently released &lt;a target="_blank" rel="nofollow" href="https://2020.stateofjs.com/"&gt;State of JS 2020 survey results&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#038;title=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" data-a2a-url="https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/" data-a2a-title="Using Node.js? The OpenJS Foundation would like to hear your feedback"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/"&gt;Using Node.js? The OpenJS Foundation would like to hear your feedback&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FTSEem2GmoI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The 2021 Node.js User Survey is now open. Node.js is an Impact Project under the OpenJS Foundation. The aim of the 2021 Node.js User Survey is to learn who is using Node.js, and how it is being used. It’s also an opportunity for Node.js users to share any feedback with the project. The survey should [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/"&gt;Using Node.js? The OpenJS Foundation would like to hear your feedback&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">865017</post-id><dc:creator>Bethany Griggs</dc:creator><dc:date>2021-02-03T08:00:25Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/</feedburner:origLink></entry><entry><title type="html">4 Easy Steps for Migrating Projects to OpenShift Container Platform</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/vq-elmSEhmE/4-easy-steps-for-migrating-projects-to-openshift-container-platform.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/1Gk5nA3g16M/4-easy-steps-for-migrating-projects-to-openshift-container-platform.html</id><updated>2021-02-03T06:00:00Z</updated><content type="html">This article is a walk through how to take an existing project, in this case I'm using a business automation project, and migrating from running locally on an application server to deploying in a container on OpenShift. The idea is to share four easy steps taking you on a journey from local to cloud native container based application deployments. The base project was an old demo project I had running on JBoss BPM Suite a few years back, polished up and now running on Red Hat Process Automation Manager using Red Hat Enterprise Application Server (EAP). The project will be outlined, followed by installing it locally on your developer machine. After that, you'll need to install the OpenShift Container Platform and I'll show you how using CodeReady Containers. This puts a container platform running on your developer machine, at which point it's a matter of installing the provided business automation operator and pushing the existing project without any changes into the container. You can observe it deploying right on your OpenShift web console or explore the details with the command line client. Ready to get started? STEP 1 - EXAMINING THE PROJECT This article brings back an old demo project, refreshed and polished up now, that is exploring how to use process automation to implement a signal.  The idea is that in this process project we are automating a loan request process where any loan up to 10,000 with a customer over 18 years old is automatically approved. The paths options can be that you might need a loan officer to physically review a loan if it's over 10,000 or it faces auto rejection if the application is made by someone younger than 18 years old. Of these three paths through the process, our fictitious marketing department wants to be notified if it's an existing customer so that they can take action, possibly marketing other services to that customer. The problem is you only want to notify the marketing department if you are sure it's a customer, and that would be anyone over 18 years of age. On top of that you want to pass on as much information as possible on the customer ot the marketing department, so you want to notify them at the end the route taken through the process. The process is not that complicated, and if you trace visually you can see the top end node is for auto rejected, the middle end node is if the loan was reviewed and approved, and the bottom end node is for reviewed applications that get rejected.  The interesting part is at the start of the process where as soon as an application is submitted, it splits to start processing on one route and to wait in a signal event node. If we submit an application that is not auto rejected, it's going to show us that it's waiting on a user review by the loan officer (red outlined node) and waiting to see if it's going to receive a signal (red outlined event node) to add a marketing contact. That wait state is only going to move onwards if we send a signal later in the process, at which time it will trigger the signal event node to proceed onwards. In this next image you see that we approved the loan and that the signal was sent in the final node before ending and the marketing contact was processed. While the initial requirements were to only signal marketing for customer contact, they later decided to track under age applications to offer them the chance to engage with potential future customers. This means we added the signalling to the last reporting node in the reject path. Let's get you started installing this on your local machine and exploring how all this works. STEP 2 - INSTALLING LOCALLY The installation is pretty straightforward and the installation script can be run after unzipping as it provides warnings for any missing software including links to download for free. Just follow the console output instructions until it completes: 1. 2. Add products to installs directory, see installs/README for details and links. 3. Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges, follow displayed instructions to start demo. After start up of the application server you can log in to (for admin and Loan Officer roles use u:erics / p:redhatpam1!) Follow the listed in the readme file. STEP 3 - INSTALLING CONTAINER PLATFORM The easiest way to install a constainter platform on your local developer machine that is exactly like the one you work with in organisations using the various public clouds, is to use the OpenShift Container Platform as provided by the CodeReady Containers product. It's available for a free download and I've outlined the few easy steps needed to , so head on over there and install it now. STEP 4 - INSTALLING TO CONTAINER The final step is now to install both the OpenShift provided operator for business automation and then push this existing project into the container. This can be done by using this project I've set up for you that automates most of it. 1. Ensure you have installed OpenShift with  which was covered in the previous section. 2. 3. Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges. Now log in to the project to start exploring how a process signal to marketing works (the address will be generated by the init script): * CodeReady Container example: ( u:erics / p:redhatpam1! ) That's all there is to it, now you can explore the installation script to see how this was done, explore the OpenShift web console to view the application container setup and deployment, and more. WHAT'S NEXT? Now that you've got a roadmap to migrating your existing projects to a container platform, and not a trivial project either, you can start exploring more of the available operators on your way to full cloud native development. Want to build more process automation projects from scratch? Try this hands-on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/vq-elmSEhmE" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/1Gk5nA3g16M/4-easy-steps-for-migrating-projects-to-openshift-container-platform.html</feedburner:origLink></entry><entry><title type="html">Quarkus Insights Q&amp;amp;A</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Mt-VXx1nVBU/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-insights-qanda/</id><updated>2021-02-02T00:00:00Z</updated><content type="html">On the next Quarkus Insights episode, we are trying something new. We will cover the most often asked questions we have seen and any question tagged with #quarkusinsights on our various social media presences: Twitter, Facebook, LinkedIn or on the youtube event directly. If you have a question about Quarkus...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Mt-VXx1nVBU" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-insights-qanda/</feedburner:origLink></entry><entry><title>How Red Hat ported OpenJDK to 64-bit Arm: A community history</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lrhdBnHEIQ0/" /><category term="Java" /><category term="Linux" /><category term="Mac" /><category term="Open source" /><category term="Windows" /><category term="64-bit ARM" /><category term="AArch64" /><category term="OpenJDK" /><category term="RHEL" /><category term="x86" /><author><name>Andrew Haley</name></author><id>https://developers.redhat.com/blog/?p=827387</id><updated>2021-02-01T08:00:42Z</updated><published>2021-02-01T08:00:42Z</published><content type="html">&lt;p&gt;It has been quite a year for Arm Ltd., the firm that designs reduced instruction set computing (RISC) architectures for computer processors. The news that Arm-based computers will be important for the foreseeable future has even reached the &lt;a target="_blank" rel="nofollow" href="https://www.nytimes.com/2020/12/01/technology/amazon-apple-chips-intel-arm.html"&gt;mainstream media&lt;/a&gt;. At the end of 2019, Amazon Web Services announced Arm-based Graviton2 servers. In June 2020, Apple announced its plans to move Macintosh computers over to Apple silicon—which means Arm.&lt;/p&gt; &lt;p&gt;For those of us who have worked for years on Arm servers, this shift has been a long time coming.&lt;/p&gt; &lt;h2&gt;In the beginning&lt;/h2&gt; &lt;p&gt;Wind back to a day in 2011. I was having lunch at The Wrestlers (the Cambridge U.K. tech community&amp;#8217;s favorite Thai eatery) with Jon Masters, Red Hat&amp;#8217;s lead Arm architect. He had exciting news to share: Arm would produce a 64-bit architecture, and Red Hat was going to port &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) to it. We&amp;#8217;d need to solve quite a few problems to get this done, but one was particularly difficult. The software then available for the new 64-bit architecture did not include &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt;. Java is a key component of much enterprise software, so this news was a pretty big deal.&lt;/p&gt; &lt;p&gt;Someone would have to write a port. I had heard that two experts could write a bare-bones port of &lt;a href="https://developers.redhat.com/products/openjdk/overview"&gt;OpenJDK&lt;/a&gt; in about a year, but that was all I knew. If my team were going to do it, we&amp;#8217;d have to learn on the job.&lt;/p&gt; &lt;p&gt;I was thrilled at the prospect of getting my teeth into such a substantial piece of work, but how could Red Hat justify starting this big project with no guarantee of success? I argued that unless we did it, we&amp;#8217;d have to pay someone. That would cost lots, so why not save money by doing it ourselves? It would be good publicity, and we&amp;#8217;d be able to build alliances. But there was another, deeper reason to keep it in-house. We&amp;#8217;d been building up a support team for OpenJDK. By writing an entire port, we&amp;#8217;d gain experience that we could not get any other way. Red Hat&amp;#8217;s management agreed (and has consistently supported the project ever since), so we were good to go.&lt;/p&gt; &lt;p&gt;I was determined to be one of the engineers on this project, but I couldn&amp;#8217;t do it alone. Fortunately, Andrew Dinn was about to join our Java team. He&amp;#8217;d worked on Java for a long time and had experience writing compilers for Lisp machines and logic languages. He&amp;#8217;d be a good fit.&lt;/p&gt; &lt;p&gt;One thing worried me: What if someone else did a port first? Then the whole effort might be wasted, along with any hope of glory. The only way to prevent that disaster was to gain first-mover advantage and do the work in public. Get it done fast, do it well, and make it free. Build it, and they will come.&lt;/p&gt; &lt;h2&gt;Starting the project&lt;/h2&gt; &lt;p&gt;We did have one problem—or rather, two. First, there was no AArch64 processor in existence. Also, persuading Arm Ltd. to give us the detailed information we needed was not easy. Persistence and help from Arm&amp;#8217;s Philippe Robin solved the documentation problem, but the lack of hardware was more difficult. It is possible to run all of OpenJDK under simulation, but the simulators at the time were painfully slow. What&amp;#8217;s worse, OpenJDK has to call out to the operating system. We would need to bootstrap all of &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; on the simulator before we could fire up Java.&lt;/p&gt; &lt;p&gt;Andrew Dinn remembers us being at breakfast at a conference when I excitedly told him that, while in the shower that morning, I&amp;#8217;d figured out what to do. We&amp;#8217;d use a simple, functional instruction set simulator, but just for the AArch64 code that we generated ourselves. The rest of the OpenJDK JVM is C++. We could run that natively at full speed on an Intel x86-based PC. Every call from C++ to Java would enter the simulator, and every call from Java back to C++ would leave the simulator and return to x86 code. But where would we get an AArch64 simulator library? &amp;#8220;We&amp;#8217;ll write one,&amp;#8221; I said. &amp;#8220;It&amp;#8217;s a RISC. How hard can it be?&amp;#8221;&lt;/p&gt; &lt;p&gt;We started in June of 2012. It took Andrew Dinn a little while to write the simulator, while I got on with writing the assembler and initial startup code. After a couple of months, we were executing Java bytecodes. The idea of writing our own simulator had been inspired. We could create complex breakpoint conditions and even record instruction traces so that we could see the instruction history when the JVM crashed. As a result, the initial porting went quickly. Looking back at the logs, I see an entry of &amp;#8220;Enough for Hello, World!&amp;#8221; on Oct 4, 2012. This was an important day: To get as far as outputting &amp;#8220;Hello, World!&amp;#8221; to the console, Java has to execute about three-quarters of a million bytecodes without crashing, and exercise much of the virtual machine.&lt;/p&gt; &lt;h2&gt;And then there were three&lt;/h2&gt; &lt;p&gt;By the summer of 2013, three of us were working on the project. Edward Nevill, a Java expert formerly of Arm Ltd., joined the project from Linaro. He was the first to get actual hardware. I was so comfortable with our little AArch64 simulator that I was very happy for someone else to debug our work on the real machine. I expected it to be a painful process. But, apart from a small problem with flushing the instruction cache and an issue with floating-point flags, it all worked! I was astonished. We&amp;#8217;d written our own simulator, compiler, and assembler from Arm&amp;#8217;s documentation. We&amp;#8217;d had no independent verification, but we&amp;#8217;d got it right.&lt;/p&gt; &lt;p&gt;Edward was a tremendous help, and by the start of 2014, we had a working port. Red Hat began shipping early releases to our partners, we and others carried on fixing bugs and improving performance, and on March 2, 2015, the AArch64 port was part of the main OpenJDK project. Oracle was great and helped and encouraged us through the tricky integration process.&lt;/p&gt; &lt;h2&gt;Consolidation and the (very) long tail&lt;/h2&gt; &lt;p&gt;There&amp;#8217;s a considerable difference between a working JVM and one that&amp;#8217;s really good. I don&amp;#8217;t know how much time has been spent on Intel/x86 OpenJDK, but it must be dozens of engineer years. It was a real challenge for us to make the AArch64 port competitive, but we had help. People from the AArch64 silicon producers and other companies joined us, and now people from all around the world are working on the port.&lt;/p&gt; &lt;p&gt;This is where Red Hat&amp;#8217;s open and collaborative approach really pays off. By forming partnerships with others, we gain a big multiplier over purely in-house software development.&lt;/p&gt; &lt;p&gt;But that&amp;#8217;s not the whole story. We&amp;#8217;d heard that Oracle was running Java on 64-bit Arm, and I wondered if it was our port. As it turned out, the port was proprietary, based on the (32-bit) Arm port Oracle already had. I was worried that Java&amp;#8217;s originator would get much better performance than we had. Eventually, someone who had used Oracle&amp;#8217;s port kindly assured me that I had nothing to worry about. I found it strange that Oracle wrote a port of its own, however. The company had permission from the beginning to use all of our code. Why write it again?&lt;/p&gt; &lt;p&gt;Eventually, Oracle freed both of its Arm 32- and 64-bit ports. That left us with two AArch64 ports in OpenJDK. Then, on November 12, 2020, Oracle &lt;a target="_blank" rel="nofollow" href="https://blogs.oracle.com/java-platform-group/update-on-64-bit-arm-support-for-oracle-openjdk-and-oracle-jdk"&gt;announced&lt;/a&gt; that it had decided to focus its resources going forward on a single 64-bit Arm port: The AArch64 port we&amp;#8217;d started at Red Hat. The 64-bit Arm support in Oracle&amp;#8217;s maintenance release of JDK 8 is now based on our port, as well.&lt;/p&gt; &lt;p&gt;Recently, with much fuss, Apple announced the Apple M1 chip, an implementation of AArch64. OpenJDK was ready for that processor and had been for five years. However, there is a layer of OpenJDK that&amp;#8217;s specific to each OS-CPU combination. Somebody had to do that work, and we soon had two volunteers: Microsoft and Azul, who worked on it together. Microsoft also ported the OS-CPU layer to Windows/AArch64.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;So, why did all this happen? The OpenJDK developer community made the decision. I believe that&amp;#8217;s because our little team stepped up with a working port early, got it into the OpenJDK mainline, and welcomed everyone who wanted to participate. We kept as many discussions as possible open. People volunteered, and we became a community. We achieved far more with this community than we ever could have hoped to do on our own. But none of it would have happened if we had not released that working port back at the start of 2014.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#038;title=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" data-a2a-url="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/" data-a2a-title="How Red Hat ported OpenJDK to 64-bit Arm: A community history"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/"&gt;How Red Hat ported OpenJDK to 64-bit Arm: A community history&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lrhdBnHEIQ0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;It has been quite a year for Arm Ltd., the firm that designs reduced instruction set computing (RISC) architectures for computer processors. The news that Arm-based computers will be important for the foreseeable future has even reached the mainstream media. At the end of 2019, Amazon Web Services announced Arm-based Graviton2 servers. In June 2020, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/"&gt;How Red Hat ported OpenJDK to 64-bit Arm: A community history&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">3</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">827387</post-id><dc:creator>Andrew Haley</dc:creator><dc:date>2021-02-01T08:00:42Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/</feedburner:origLink></entry><entry><title>Write a Quarkus function in two steps on Red Hat OpenShift Serverless</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gxUrQoW2pXk/" /><category term="Java" /><category term="Kubernetes" /><category term="Quarkus" /><category term="Serverless" /><category term="Knative" /><category term="openshift" /><category term="Quarkus functions" /><category term="serverless functions" /><author><name>Daniel Oh</name></author><id>https://developers.redhat.com/blog/?p=853867</id><updated>2021-01-29T08:00:57Z</updated><published>2021-01-29T08:00:57Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2021/01/04/create-your-first-serverless-function-with-red-hat-openshift-serverless-functions/"&gt;Serverless functions&lt;/a&gt; are driving the fast adoption of DevApps development and deployment practices today. To successfully adopt serverless functions, developers must understand how serverless capabilities are specified using a combination of cloud computing, data infrastructure, and function-oriented programming. We also need to consider resource optimization (memory and CPU) and high-performance boot and first-response times in both development and production environments. What if we didn&amp;#8217;t have to worry about all of that?&lt;/p&gt; &lt;p&gt;In this article, I&amp;#8217;ll walk you through two steps to write a serverless function with superfast boot and response times and built-in resource optimization. First, we&amp;#8217;ll use a pre-defined &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; function project template to write a serverless function. Then, we&amp;#8217;ll deploy the function as a native executable using &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Red Hat OpenShift Serverless&lt;/a&gt;. With these two steps, we can avoid the extra work of developing a function from scratch, optimizing the application, and deploying it as a &lt;a href="https://developers.redhat.com/topics/serverless-architecture#assembly-field-sections-38375"&gt;Knative&lt;/a&gt; service in &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Step 1: Create a Quarkus function project&lt;/h2&gt; &lt;p&gt;The Knative command-line interface (&lt;code&gt;kn&lt;/code&gt;) supports simple interactions with Knative components on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift Container Platform&lt;/a&gt;. In this step, we&amp;#8217;ll use &lt;code&gt;kn&lt;/code&gt; to create a new function project based on the Quarkus runtime. See the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/serverless/installing_serverless/installing-kn.html"&gt;OpenShift Serverless documentation&lt;/a&gt; for instructions to install &lt;code&gt;kn&lt;/code&gt; for your operating system.&lt;/p&gt; &lt;p&gt;Assuming you have &lt;code&gt;kn&lt;/code&gt; installed, move to a preferred directory in your local development environment. Then, execute the following command in your terminal:&lt;/p&gt; &lt;pre&gt;$ kn func create quarkus-func -l quarkus &lt;/pre&gt; &lt;p&gt;The command generates a &lt;code&gt;quarkus-func&lt;/code&gt; directory that includes a new Quarkus project. Here&amp;#8217;s the output for our example:&lt;/p&gt; &lt;pre&gt;Project path: /Users/danieloh/Downloads/func-demo/quarkus-func Function name: quarkus-func Runtime: quarkus Trigger: http &lt;/pre&gt; &lt;p&gt;Next, use a text editor or your favorite IDE to open a &lt;code&gt;func.yaml&lt;/code&gt; file in the &lt;code&gt;quarkus-func&lt;/code&gt; project. Update the builder’s value to &lt;em&gt;native&lt;/em&gt; for building a Quarkus native executable. The native executable allows you to get Quarkus&amp;#8217;s superfast boot and first-response times and subatomic memory footprint. You should see something like this:&lt;/p&gt; &lt;pre&gt;name: quarkus-func namespace: "" runtime: quarkus image: "" imageDigest: "" trigger: http builder: native builderMap:   default: quay.io/boson/faas-quarkus-jvm-builder  jvm: quay.io/boson/faas-quarkus-jvm-builder  native: quay.io/boson/faas-quarkus-native-builder envVars: {} &lt;/pre&gt; &lt;p&gt;That&amp;#8217;s it. We can move forward to the next step, which is also the last step.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;kn&lt;/code&gt; CLI does not include a login mechanism. To log in to your OpenShift cluster, in the next step, you will need to have the &lt;code&gt;oc&lt;/code&gt; CLI installed. Once it&amp;#8217;s installed, you can use the &lt;code&gt;oc login&lt;/code&gt; command. Installation options for &lt;code&gt;oc&lt;/code&gt; will vary depending on your operating system. For more information, see the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/cli_reference/openshift_cli/getting-started-cli.html#cli-getting-started"&gt;OpenShift CLI documentation&lt;/a&gt;. Furthermore, we’ll use OpenShift Serverless features to deploy a serverless function, so you must install the OpenShift Serverless Operator to your OpenShift cluster. See the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/serverless/installing_serverless/installing-openshift-serverless.html"&gt;OpenShift Serverless documentation&lt;/a&gt; for more about installation.&lt;/p&gt; &lt;h2&gt;Step 2: Deploy a Quarkus function to OpenShift Serverless&lt;/h2&gt; &lt;p&gt;In this step, we&amp;#8217;ll build and deploy a container image based on the Quarkus function we&amp;#8217;ve just created. To start, move your working directory to the Quarkus project. Then, run the following commands in your terminal:&lt;/p&gt; &lt;pre&gt;$ oc new-project quarkus-func $ cd quarkus-func $ kn func deploy -r registry_string -n quarkus-func -v &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Be sure to replace the above &lt;code&gt;registry_string&lt;/code&gt; (&lt;code&gt;quay.io/myuser&lt;/code&gt; or &lt;code&gt;docker.io/myuser&lt;/code&gt;) with your own registry and namespace.&lt;/p&gt; &lt;p&gt;It takes a few minutes to build a native executable and containerize the application, which we&amp;#8217;ll do using &lt;a target="_blank" rel="nofollow" href="https://github.com/boson-project/buildpacks"&gt;Boson Project Buildpacks&lt;/a&gt;. Buildpacks automate the process of converting a user&amp;#8217;s function from source code into a runnable &lt;a target="_blank" rel="nofollow" href="https://github.com/opencontainers/image-spec"&gt;OCI image&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You will see the following message once the Knative service deploys the function to your OpenShift cluster:&lt;/p&gt; &lt;pre&gt;Deploying function to the cluster Creating Knative Service: quarkus--func Waiting for Knative Service to become ready Function deployed at URL: http://quarkus--func-quarkus-func.apps.cluster-boston-c079.boston-c079.sandbox1545.opentlc.com &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The deployment URL in this output will be different for your environment.&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s add a &lt;code&gt;label&lt;/code&gt; to the Quarkus pod for fun. Run the following commands:&lt;/p&gt; &lt;pre&gt;$ REV_NAME=$(oc get rev | awk '{print $1}') $ oc label rev/$REV_NAME app.openshift.io/runtime=quarkus --overwrite &lt;/pre&gt; &lt;p&gt;Next, go to the developer console in your OpenShift cluster and navigate to the Topology view, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_853887" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853887" class="wp-image-853887 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM-1024x623.png" alt="A Quarkus function in the OpenShift Topology view." width="640" height="389" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM-1024x623.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM-300x182.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM-768x467.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM.png 1362w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853887" class="wp-caption-text"&gt;Figure 1: Find your Quarkus serverless function in the Topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The serverless function might be terminated because the scale-to-zero interval is 30 seconds by default. We can fire up the function by entering the following command:&lt;/p&gt; &lt;pre&gt;$ curl -v FUNC_URL  \  -H 'Content-Type:application/json' \   -d '{"message": "Quarkus Native function on OpenShift Serverless"}' &lt;/pre&gt; &lt;p&gt;You should see something like this:&lt;/p&gt; &lt;pre&gt;... * Connection #0 to host quarkus--func-quarkus-func.apps.cluster-boston-c079.boston-c079.sandbox1545.opentlc.com left intact {"message":"Quarkus Native function on OpenShift Serverless"}* Closing connection 0 &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Be sure to replace the above &lt;code&gt;FUNC_URL&lt;/code&gt; with your own URL, which should be the same as the deployment URL in the previous step. (You can also find it by entering &lt;code&gt;oc get rt&lt;/code&gt;.)&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s go back to the developer console. Sending traffic to the endpoint triggers the autoscaler to scale the function, so you&amp;#8217;ll see that the Quarkus function pod has gone up automatically, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_853897" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853897" class="wp-image-853897 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM-1024x464.png" alt="The Quarkus function pod in the Topology view." width="640" height="290" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM-1024x464.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM-300x136.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM-768x348.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM.png 1536w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853897" class="wp-caption-text"&gt;Figure 2: The autoscaler automatically scales the Quarkus function pod.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Click the &lt;b&gt;View logs&lt;/b&gt; option in Figure 3 to discover the application&amp;#8217;s amazingly fast startup time.&lt;/p&gt; &lt;div id="attachment_853907" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853907" class="wp-image-853907 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM-1024x552.png" alt="Check the Resources view in the logs." width="640" height="345" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM-1024x552.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM-300x162.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM-768x414.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853907" class="wp-caption-text"&gt;Figure 3: Click View logs in the Resources view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You should see something like the startup time shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_853917" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853917" class="wp-image-853917 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM-1024x227.png" alt="The startup time is 30 milliseconds." width="640" height="142" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM-1024x227.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM-300x66.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM-768x170.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853917" class="wp-caption-text"&gt;Figure 4: The pod logs show a startup time of 30 milliseconds.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In my example, the application took &lt;em&gt;30 milliseconds&lt;/em&gt; to start up. The startup time might be different in your environment.&lt;/p&gt; &lt;p&gt;Finally, if you want to check the (extremely low) memory usage while the function is running, go to the &lt;strong&gt;Monitoring&lt;/strong&gt; page and check the memory usage in metrics, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_853927" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853927" class="wp-image-853927 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM-1024x659.png" alt="The memory usage metrics page shows that the process takes around 78MB of memory." width="640" height="412" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM-1024x659.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM-300x193.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM-768x494.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853927" class="wp-caption-text"&gt;Figure 5: Memory usage while the function is running.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This shows that our process is taking around 78MB of memory footprint. That&amp;#8217;s pretty compact!&lt;/p&gt; &lt;h3&gt;Conclusion&lt;/h3&gt; &lt;p&gt;This article showed you how to use OpenShift Serverless to create a function based on the Quarkus runtime with native compilation, then deploy it to an OpenShift cluster with just &lt;em&gt;two&lt;/em&gt; &lt;code&gt;kn func&lt;/code&gt; commands. It&amp;#8217;s also possible to choose a different function runtime (such as &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; or &lt;a href="https://developers.redhat.com/blog/category/go/"&gt;Go&lt;/a&gt;) and function trigger (such as HTTP or CloudEvents) than we used for this example. For a guide to creating a front-end application with a Node.js runtime and OpenShift Serverless, see &lt;a href="https://developers.redhat.com/blog/2021/01/04/create-your-first-serverless-function-with-red-hat-openshift-serverless-functions/"&gt;&lt;i&gt;Create your first serverless function with Red Hat OpenShift Serverless Functions&lt;/i&gt;&lt;/a&gt;. For more about Quarkus&amp;#8217;s serverless strategy, see &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/funqy"&gt;Quarkus Funqy&lt;/a&gt;—a portable Java API that you can use to write functions deployable to Function-as-a-Service (FaaS) environments like AWS Lambda, Azure Functions, &lt;a href="https://developers.redhat.com/coderland/serverless/serverless-knative-intro"&gt;Knative&lt;/a&gt;, and Knative Events.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#038;title=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" data-a2a-url="https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/" data-a2a-title="Write a Quarkus function in two steps on Red Hat OpenShift Serverless"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/"&gt;Write a Quarkus function in two steps on Red Hat OpenShift Serverless&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gxUrQoW2pXk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Serverless functions are driving the fast adoption of DevApps development and deployment practices today. To successfully adopt serverless functions, developers must understand how serverless capabilities are specified using a combination of cloud computing, data infrastructure, and function-oriented programming. We also need to consider resource optimization (memory and CPU) and high-performance boot and first-response times in [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/"&gt;Write a Quarkus function in two steps on Red Hat OpenShift Serverless&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">853867</post-id><dc:creator>Daniel Oh</dc:creator><dc:date>2021-01-29T08:00:57Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/</feedburner:origLink></entry></feed>
