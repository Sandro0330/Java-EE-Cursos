<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Spring Boot on Quarkus: Magic or madness?</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Rubsp5_qZac/" /><category term="Java" /><category term="Microservices" /><category term="Open source" /><category term="Quarkus" /><category term="Spring Boot" /><category term="Migration" /><category term="Quarkus migration" /><category term="Spring Boot migration" /><author><name>Eric Deandrea</name></author><id>https://developers.redhat.com/blog/?p=855487</id><updated>2021-02-09T08:00:58Z</updated><published>2021-02-09T08:00:58Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io"&gt;Quarkus&lt;/a&gt; is a &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; stack tailored for OpenJDK HotSpot (or OpenJ9 on zSeries) and GraalVM, crafted from optimized Java libraries and standards. It is a good choice for building highly-scalable applications while using lower amounts of CPU and memory resources than other Java frameworks. These applications can be traditional web applications, serverless applications, or even &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/funqy"&gt;functions as a service&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;There are &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/blog/tag/user-story/"&gt;many documented instances&lt;/a&gt; of organizations migrating their applications to Quarkus. In this article, let&amp;#8217;s see one such migration path from &lt;a target="_blank" rel="nofollow" href="https://spring.io/projects/spring-boot"&gt;Spring Boot&lt;/a&gt; to Quarkus that is part magic and part madness! The magic will be some hand waving and performing the migration without changing a single line of code. The madness will be trying to figure out how it was done.&lt;/p&gt; &lt;h2&gt;The Application&lt;/h2&gt; &lt;p&gt;The application is a simple “to-do” task management system. The user can enter to-do items and then check them off once done. These items are stored in a &lt;a target="_blank" rel="nofollow" href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; database. All the application’s source code can be found &lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus"&gt;here&lt;/a&gt;. There’s a version that uses &lt;a target="_blank" rel="nofollow" href="https://gradle.org/"&gt;Gradle&lt;/a&gt; instead of &lt;a target="_blank" rel="nofollow" href="https://maven.apache.org/"&gt;Maven&lt;/a&gt; as a build tool on the &lt;code&gt;gradle&lt;/code&gt; branch.&lt;/p&gt; &lt;h3&gt;Start the database&lt;/h3&gt; &lt;p&gt;The application requires a PostgreSQL database, so the first thing we will do is use Docker or &lt;a target="_blank" rel="nofollow" href="https://podman.io/"&gt;Podman&lt;/a&gt; to start an instance locally:&lt;/p&gt; &lt;pre&gt;docker run --ulimit memlock=-1:-1 -it --rm=true --memory-swappiness=0 --name tododb -e POSTGRES_USER=todo -e POSTGRES_PASSWORD=todo -e POSTGRES_DB=tododb -p 5432:5432 postgres:11.5 &lt;/pre&gt; &lt;p&gt;A PostgreSQL 11.5 instance on port 5432 should now be running. The &lt;code&gt;tododb&lt;/code&gt; schema accessible by the user &lt;code&gt;todo&lt;/code&gt; with the password &lt;code&gt;todo&lt;/code&gt; should be created.&lt;/p&gt; &lt;h3&gt;Run the application&lt;/h3&gt; &lt;p&gt;Run the application by issuing the command &lt;code&gt;./mvnw clean spring-boot:run&lt;/code&gt;. If you want to use Gradle instead of Maven, first switch to the &lt;code&gt;gradle&lt;/code&gt; branch (&lt;code&gt;git checkout gradle&lt;/code&gt;) and run the command &lt;code&gt;./gradlew clean bootRun&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;You should see the standard Spring Boot banner:&lt;/p&gt; &lt;pre&gt; .   ____          _            __ _ _ /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \ \\/  ___)| |_)| | | | | || (_| |  ) ) ) ) '  |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot ::                (v2.4.1) INFO 68107 --- [  restartedMain] i.q.todospringquarkus.TodoApplication    : Started TodoApplication in 4.074 seconds (JVM running for 4.645) &lt;/pre&gt; &lt;p&gt;Take note of the startup time. We’ll revisit this in a bit.&lt;/p&gt; &lt;p&gt;Once the application is running, navigate to &lt;a target="_blank" rel="nofollow" href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; in your favorite browser.  You should see the main application screen as shown here in Figure 1.&lt;/p&gt; &lt;div id="attachment_855717" style="width: 651px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/spring-todo-1.png"&gt;&lt;img aria-describedby="caption-attachment-855717" class="wp-image-855717" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/spring-todo-1.png" alt="The Spring Todos application with &amp;#34;My first todo&amp;#34; marked as complete." width="641" height="436" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/spring-todo-1.png 676w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/spring-todo-1-300x204.png 300w" sizes="(max-width: 641px) 100vw, 641px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-855717" class="wp-caption-text"&gt;Figure 1: Initial application screen.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Play around with the application a bit. Type a new todo into the text box and press Enter. That todo will show up in the list, as seen here in Figure 2.&lt;/p&gt; &lt;div id="attachment_855727" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/spring-todo-2.png"&gt;&lt;img aria-describedby="caption-attachment-855727" class="wp-image-855727" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/spring-todo-2.png" alt="Spring Todos with the new todo added to the list." width="640" height="434" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/spring-todo-2.png 667w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/spring-todo-2-300x203.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-855727" class="wp-caption-text"&gt;Figure 2: Add a new todo.&lt;/p&gt;&lt;/div&gt; &lt;ol&gt; &lt;li&gt;Click the empty circle next to a todo to complete it, or uncheck it to mark it as incomplete.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;X&lt;/strong&gt; to remove a todo.&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;OpenAPI&lt;/strong&gt; link at the bottom of the page will open the OpenAPI 3.0 specification for the application.&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;Swagger UI&lt;/strong&gt; link opens the embedded &lt;a target="_blank" rel="nofollow" href="https://swagger.io/tools/swagger-ui/"&gt;Swagger UI&lt;/a&gt;, which can be used to execute some of the &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Representational_state_transfer"&gt;RESTful endpoints&lt;/a&gt; directly.&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;Prometheus Metrics&lt;/strong&gt; link leads to the &lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-features.html#production-ready-metrics-export-prometheus"&gt;Prometheus metrics endpoint&lt;/a&gt;, which would be scraped intermittently by &lt;a target="_blank" rel="nofollow" href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;Health Check&lt;/strong&gt; link opens the &lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-features.html#production-ready-health"&gt;built-in health check&lt;/a&gt; exposed by Spring Boot.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Go ahead and play around a bit to see it all in action. Don’t forget to come back here once you’re done! Use &lt;code&gt;CTRL-C&lt;/code&gt; on your keyboard to stop the application once you’re done.&lt;/p&gt; &lt;h3&gt;Examine the internals&lt;/h3&gt; &lt;p&gt;The application is a full-featured Spring Boot application using the following capabilities:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-framework/docs/current/reference/html/web.html"&gt;Spring MVC&lt;/a&gt; for building a REST layer: &lt;ul&gt; &lt;li&gt;Open &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/src/main/java/io/quarkus/todospringquarkus/TodoController.java"&gt;src/main/java/io/quarkus/todospringquarkus/TodoController.java&lt;/a&gt;&lt;/code&gt; to find the Spring MVC RESTful controller, exposing the various endpoints available to the user interface.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-data/jpa/docs/current/reference/html"&gt;Spring Data JPA&lt;/a&gt; for defining relational entities as well as storing and retrieving them: &lt;ul&gt; &lt;li&gt;Open &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/src/main/java/io/quarkus/todospringquarkus/TodoEntity.java"&gt;src/main/java/io/quarkus/todospringquarkus/TodoEntity.java&lt;/a&gt;&lt;/code&gt; to find the &lt;a target="_blank" rel="nofollow" href="https://www.oracle.com/java/technologies/persistence-jsp.html"&gt;Java Persistence API (JPA)&lt;/a&gt; entity, representing the relational table for storing the todos.&lt;/li&gt; &lt;li&gt;Open &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/src/main/java/io/quarkus/todospringquarkus/TodoRepository.java"&gt;src/main/java/io/quarkus/todospringquarkus/TodoRepository.java&lt;/a&gt; &lt;/code&gt;to find the &lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#repositories"&gt;Spring Data JPA Repository&lt;/a&gt;, exposing all of the create, read, update, and delete operations for the TodoEntity.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-features.html"&gt;Spring Boot Actuators&lt;/a&gt; for providing operational capabilities, including health checks and metrics gathering.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://springdoc.org/"&gt;SpringDoc OpenAPI 3&lt;/a&gt; for generating and exposing RESTful API information as well as the embedded Swagger UI endpoint.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://micrometer.io/docs/registry/prometheus"&gt;Prometheus Micrometer Registry&lt;/a&gt; for exposing metrics to Prometheus.&lt;/li&gt; &lt;li&gt;Open &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/tree/main/src/main/resources/META-INF/resources"&gt;src/main/resources/META-INF/resources&lt;/a&gt;&lt;/code&gt; to find the user interface components used.&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Configuration&lt;/h4&gt; &lt;p&gt;Open &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/src/main/resources/application.properties"&gt;src/main/resources/application.properties&lt;/a&gt;&lt;/code&gt; to find the application configuration:&lt;/p&gt; &lt;pre&gt;spring.jpa.hibernate.ddl-auto=create-drop spring.datasource.url=jdbc:postgresql://localhost:5432/tododb spring.datasource.username=todo spring.datasource.password=todo springdoc.api-docs.path=/openapi springdoc.swagger-ui.path=/swagger-ui management.endpoints.web.exposure.include=prometheus,health &lt;/pre&gt; &lt;p&gt;Open &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/src/main/resources/import.sql"&gt;src/main/resources/import.sql&lt;/a&gt;&lt;/code&gt; to find some SQL that will pre-populate the database table with an initial set of data:&lt;/p&gt; &lt;pre&gt;INSERT INTO todo(id, title, completed) VALUES (0, 'My first todo', 'true'); &lt;/pre&gt; &lt;p&gt;That’s it Not a lot of code here for a fully-functional application that’s a whole lot more than “Hello World!”&lt;/p&gt; &lt;h2&gt;The Magic&lt;/h2&gt; &lt;p&gt;One hard requirement for this migration has been chosen: The application’s source code cannot be modified in any way.&lt;/p&gt; &lt;p&gt;Are you ready for the magic trick? Return to the command line and run the command &lt;code&gt;./.mvnw clean spring-boot:run&lt;/code&gt;. If you want to use Gradle instead of Maven, first switch to the &lt;code&gt;gradle&lt;/code&gt; branch (&lt;code&gt;git checkout gradle&lt;/code&gt;) and run the command &lt;code&gt;./.gradlew clean bootRun&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The first thing you’ll notice is the Quarkus banner and startup messaging instead of the Spring Boot one:&lt;/p&gt; &lt;pre&gt;__  ____  __  _____   ___  __ ____  ______ --/ __ \/ / / / _ | / _ \/ //_/ / / / __/ -/ /_/ / /_/ / __ |/ , _/ ,&amp;#60; / /_/ /\ \ --\___\_\____/_/ |_/_/|_/_/|_|\____/___/ INFO  [io.quarkus] (Quarkus Main Thread) todo-spring-quarkus 1.0.0-SNAPSHOT on JVM (powered by Quarkus 1.10.5.Final) started in 2.743s. Listening on: http://localhost:8080 INFO  [io.quarkus] (Quarkus Main Thread) Profile dev activated. Live Coding activated. INFO  [io.quarkus] (Quarkus Main Thread) Installed features: [agroal, cdi, hibernate-orm, hibernate-orm-panache, jdbc-postgresql, kubernetes, micrometer, mutiny, narayana-jta, resteasy, resteasy-jackson, smallrye-context-propagation, smallrye-health, smallrye-openapi, spring-boot-properties, spring-data-jpa, spring-di, spring-web, swagger-ui] &lt;/pre&gt; &lt;p&gt;Wait, what just happened? The application is now a Quarkus application and no longer a Spring Boot application? That’s madness!&lt;/p&gt; &lt;p&gt;Want proof? Go back to your browser window (&lt;a target="_blank" rel="nofollow" href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; in case you closed it) and reload the page. The same user interface is there and is completely functional. Click on all the various links at the bottom of the page. They’re all completely functional as they were before.&lt;/p&gt; &lt;p&gt;Also, note the startup time. The Quarkus version starts up in almost half the amount of time given the exact same codebase (4.074s for Spring vs. 2.743s for Quarkus in the shown examples). That&amp;#8217;s Supersonic, Subatomic, Java!&lt;/p&gt; &lt;p&gt;Nothing changed, so how did all this happen? A good magician doesn’t reveal his or her secrets!&lt;/p&gt; &lt;h2&gt;The Madness&lt;/h2&gt; &lt;p&gt;All good magicians use &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Sleight_of_hand"&gt;sleight-of-hand&lt;/a&gt; to distract his or her audience when performing a trick. There are a few things that weren’t shown yet in this post that are hidden from the naked eye. Did you notice anything suspicious? Let’s take a closer look at how the trick was done.&lt;/p&gt; &lt;h3&gt;Execution&lt;/h3&gt; &lt;p&gt;Look very closely at the commands you used to run the application:&lt;/p&gt; &lt;p&gt;Using Maven:&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;Spring Boot: &lt;code&gt;./mvnw clean spring-boot:run&lt;/code&gt;&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;Quarkus: &lt;code&gt;./.mvnw clean spring-boot:run&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Using Gradle:&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;Spring Boot: &lt;code&gt;./gradlew clean bootRun&lt;/code&gt;&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;Quarkus: &lt;code&gt;./.gradlew clean bootRun&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Notice any differences? A different executable (&lt;code&gt;.mvnw&lt;/code&gt;/&lt;code&gt;.gradlew&lt;/code&gt;) is used in the Quarkus version. If you open those files and examine them closely, you’ll notice some trickery going on:&lt;/p&gt; &lt;p&gt;&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/.mvnw"&gt;.mvnw&lt;/a&gt;&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;#!/bin/sh ./mvnw clean quarkus:dev -Pquarkus &lt;/pre&gt; &lt;p&gt;&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/gradle/.gradlew"&gt;.gradlew&lt;/a&gt;&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;#!/bin/sh ./gradlew -Pprofile=quarkus $@ &lt;/pre&gt; &lt;p&gt;We used some sleight-of-hand to disguise the actual commands used to start the application. More on Gradle and Maven profiles later.&lt;/p&gt; &lt;h3&gt;Configuration&lt;/h3&gt; &lt;p&gt;Are you saying that Quarkus knows how to read and understand the Spring Boot configuration inside &lt;code&gt;src/main/resources/application.properties&lt;/code&gt;? Well, no. Remember, this is a magic trick. A magician never tells the complete truth. What wasn’t shown in the example above is the Quarkus-specific configuration. It was hidden further down in the file.&lt;/p&gt; &lt;p&gt;If you re-open &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/src/main/resources/application.properties"&gt;src/main/resources/application.properties&lt;/a&gt;&lt;/code&gt; and scroll all the way to the bottom (around line 58) you’ll see some additional configuration:&lt;/p&gt; &lt;pre&gt;quarkus.datasource.db-kind=postgresql quarkus.datasource.jdbc.url=jdbc:postgresql://localhost:5432/tododb quarkus.datasource.username=todo quarkus.datasource.password=todo quarkus.datasource.metrics.enabled=true quarkus.hibernate-orm.database.generation=drop-and-create quarkus.hibernate-orm.sql-load-script=import.sql quarkus.micrometer.export.prometheus.path=/actuator/prometheus quarkus.smallrye-health.root-path=/actuator/health &lt;/pre&gt; &lt;p&gt;This configuration is similar to the Spring Boot configuration at the top of the file. One thing it does do, however, is to re-define the paths for the Prometheus and the health probe endpoints, so they match the paths of the Spring Boot actuator endpoints. This allows the &lt;strong&gt;Prometheus Metrics&lt;/strong&gt; and &lt;strong&gt;Health Check&lt;/strong&gt; links at the bottom of the screen to work without any changes to the user interface.&lt;/p&gt; &lt;p&gt;Pretty sneaky, huh?&lt;/p&gt; &lt;h3&gt;Dependencies&lt;/h3&gt; &lt;p&gt;As you can imagine, there are lots of dependencies that need to be changed, added, or updated. Luckily, Quarkus provides many Spring compatibility extensions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/spring-di"&gt;Quarkus extension for Spring Dependency Injection&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/spring-web"&gt;Quarkus extension for Spring Web&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/spring-data-jpa"&gt;Quarkus extension for Spring Data JPA&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/spring-boot-properties"&gt;Quarkus extension for Spring Boot Properties&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Simply swapping some of the Spring Boot dependencies for the Quarkus ones will go a long way. There are a few other capabilities, such as Prometheus metrics, OpenAPI documentation, Swagger UI integration, and health checks that need other dependencies added. Lucky for us again, Quarkus has these capabilities as well:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/openapi-swaggerui"&gt;Quarkus extension for OpenAPI and Swagger UI&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/microprofile-health"&gt;Quarkus extension for MicroProfile Health&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/micrometer"&gt;Quarkus extension for Micrometer Metrics&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Now you’re probably thinking to yourself, “But I didn’t make ANY changes whatsoever. All I did was run a Maven or Gradle command, and the entire application ran as a Quarkus application instead of a Spring Boot application. How can that be?”&lt;/p&gt; &lt;h3&gt;Build setup&lt;/h3&gt; &lt;p&gt;The build file is where all the magic happens. The build tool you are using determines how the dependency resolution magic actually happens, though.&lt;/p&gt; &lt;h4&gt;Maven&lt;/h4&gt; &lt;p&gt;On the &lt;code&gt;main&lt;/code&gt; branch, open the &lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/pom.xml"&gt;&lt;code&gt;pom.xml&lt;/code&gt;&lt;/a&gt; file. You’ll immediately notice the build file is broken into multiple &lt;a target="_blank" rel="nofollow" href="https://maven.apache.org/guides/introduction/introduction-to-profiles.html"&gt;Maven profiles&lt;/a&gt;, &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/pom.xml#L26-L99"&gt;spring&lt;/a&gt;&lt;/code&gt; and &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/pom.xml#L100-L195"&gt;quarkus&lt;/a&gt;&lt;/code&gt;, with the &lt;code&gt;spring&lt;/code&gt; profile being the default profile. These profiles define which dependencies and build plugins are included when you run either &lt;code&gt;./mvnw clean spring-boot:run&lt;/code&gt; or &lt;code&gt;./mvnw -Pquarkus clean quarkus:dev&lt;/code&gt; (which is disguised using some redirection in the aforementioned &lt;code&gt;.mvnw&lt;/code&gt; script).&lt;/p&gt; &lt;h4&gt;Gradle&lt;/h4&gt; &lt;p&gt;Gradle, on the other hand, does not have the concept of a profile. You’ll notice a handful of &lt;code&gt;.gradle&lt;/code&gt; files in the &lt;code&gt;gradle&lt;/code&gt; branch of the project:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/gradle/build-common.gradle"&gt;build-common.gradle&lt;/a&gt;&lt;/code&gt; &lt;ul&gt; &lt;li&gt;Contains any common build logic applicable to both versions of the application, including setting the groupId/version of the produced artifact as well as artifact repository definitions.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/gradle/build-spring.gradle"&gt;build-spring.gradle&lt;/a&gt;&lt;/code&gt; &lt;ul&gt; &lt;li&gt;Contains all build logic, plugins, and dependencies specific to the Spring version of the application.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/gradle/build-quarkus.gradle"&gt;build-quarkus.gradle&lt;/a&gt;&lt;/code&gt; &lt;ul&gt; &lt;li&gt;Contains all build logic, plugins, and dependencies specific to the Quarkus version of the application. &lt;code&gt;build-quarkus.gradle&lt;/code&gt; even introduces &lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/htmlsingle/#running-your-application"&gt;Spring Boot’s &lt;code&gt;bootRun&lt;/code&gt;&lt;/a&gt; task, re-mapping it to the &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/gradle-tooling#development-mode"&gt;quarkusDev&lt;/a&gt;&lt;/code&gt; task from the &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/gradle-tooling"&gt;Quarkus Gradle plugin.&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/gradle/settings.gradle"&gt;settings.gradle&lt;/a&gt;&lt;/code&gt; &lt;ul&gt; &lt;li&gt;Where the magic actually happens! The &lt;code&gt;settings.gradle&lt;/code&gt; file looks for a &lt;a target="_blank" rel="nofollow" href="https://docs.gradle.org/current/userguide/build_environment.html#sec:project_properties"&gt;Gradle project property&lt;/a&gt; called &lt;code&gt;profile&lt;/code&gt;: &lt;ul&gt; &lt;li&gt;If this property isn’t found, it defaults the value to &lt;code&gt;spring&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;It then sets the project’s build file, either &lt;code&gt;build-spring.gradle&lt;/code&gt; or &lt;code&gt;build-quarkus.gradle&lt;/code&gt;, as the main build file to use.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In general, this is a pretty good pattern to use if you need Gradle to simulate the capabilities of Maven profiles.&lt;/p&gt; &lt;h3&gt;Application Main Class&lt;/h3&gt; &lt;p&gt;It was mentioned at the beginning of this post that we wanted to perform the migration without changing a single line of code. Every Spring Boot application needs to have an “application” class that contains a &lt;code&gt;main&lt;/code&gt; method and is annotated with &lt;code&gt;@SpringBootApplication&lt;/code&gt;. In our project, &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/src/main/java/io/quarkus/todospringquarkus/TodoApplication.java"&gt;src/main/java/io/quarkus/todospringquarkus/TodoApplication.java&lt;/a&gt;&lt;/code&gt; is that class.&lt;/p&gt; &lt;p&gt;Quarkus does not require such a class, nor do any of the Quarkus Spring compatibility extensions provide resolution for the &lt;code&gt;@SpringBootApplication&lt;/code&gt; annotation nor the &lt;code&gt;SpringApplication&lt;/code&gt; class referenced in this class.&lt;/p&gt; &lt;p&gt;So, what gives? We didn’t make any code changes whatsoever, yet those classes seem to resolve just fine in Quarkus.&lt;/p&gt; &lt;p&gt;You’ll notice a peculiar comment in both &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/main/pom.xml#L16"&gt;pom.xml&lt;/a&gt;&lt;/code&gt; (for Maven)/&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/edeandrea/todo-spring-quarkus/blob/gradle/build-quarkus.gradle#L23"&gt;build-quarkus.gradle&lt;/a&gt;&lt;/code&gt; (for Gradle), right above the dependency declaration for the dependency &lt;code&gt;org.springframework.boot:spring-boot-autoconfigure&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;This dependency is a hack for TodoApplication.java, which isn't required for Quarkus. Point of demo is to NOT have any code changes. &lt;/pre&gt; &lt;p&gt;This is the key to this part of the trick. This dependency allows both Spring Boot and Quarkus to resolve these classes at build time. The dependency is declared &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://maven.apache.org/guides/introduction/introduction-to-optional-and-excludes-dependencies.html#optional-dependencies"&gt;optional&lt;/a&gt;&lt;/code&gt; in Maven/&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://blog.gradle.org/introducing-compile-only-dependencies"&gt;compileOnly&lt;/a&gt;&lt;/code&gt; in Gradle, meaning it will never be included in the application binary the Quarkus build produces. It will be included in the binary the Spring Boot build produces because all of the other &lt;code&gt;spring-boot-starter-*&lt;/code&gt; dependencies also depend on it, so it&amp;#8217;s included transitively.&lt;/p&gt; &lt;h2&gt;Wrap Up&lt;/h2&gt; &lt;p&gt;You saw in this post how to take an existing Spring Boot application and run it on Quarkus without making a single change to the code. Was the method magic or madness? Maybe a little bit of both? It&amp;#8217;s up to you to decide for yourself.&lt;/p&gt; &lt;p&gt;This post showed one way to migrate an application that is more than “Hello World” from Spring Boot to Quarkus with a hard requirement of not changing a single line of source code. It isn’t at all intended to represent the only potential migration path. Furthermore, there may be times when an application uses some library or API where there isn’t a Quarkus equivalent. In those cases, there may be code changes or some refactoring necessary.&lt;/p&gt; &lt;p&gt;A big thanks to &lt;a href="https://developers.redhat.com/authors/eric-murphy"&gt;Eric Murphy&lt;/a&gt;. He is the original author of the application and came up with the magic trick idea.&lt;/p&gt; &lt;h2&gt;References&lt;/h2&gt; &lt;p&gt;All source code for this post can be found &lt;a target="_blank" rel="nofollow" href="http://github.com/edeandrea/todo-spring-quarkus"&gt;here&lt;/a&gt;. The &lt;code&gt;main&lt;/code&gt; branch contains the Maven version, and the &lt;code&gt;gradle&lt;/code&gt; branch contains the Gradle version. The application source code is the same on both branches.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F09%2Fspring-boot-on-quarkus-magic-or-madness%2F&amp;#38;linkname=Spring%20Boot%20on%20Quarkus%3A%20Magic%20or%20madness%3F" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F09%2Fspring-boot-on-quarkus-magic-or-madness%2F&amp;#38;linkname=Spring%20Boot%20on%20Quarkus%3A%20Magic%20or%20madness%3F" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F09%2Fspring-boot-on-quarkus-magic-or-madness%2F&amp;#38;linkname=Spring%20Boot%20on%20Quarkus%3A%20Magic%20or%20madness%3F" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F09%2Fspring-boot-on-quarkus-magic-or-madness%2F&amp;#38;linkname=Spring%20Boot%20on%20Quarkus%3A%20Magic%20or%20madness%3F" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F09%2Fspring-boot-on-quarkus-magic-or-madness%2F&amp;#38;linkname=Spring%20Boot%20on%20Quarkus%3A%20Magic%20or%20madness%3F" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F09%2Fspring-boot-on-quarkus-magic-or-madness%2F&amp;#38;linkname=Spring%20Boot%20on%20Quarkus%3A%20Magic%20or%20madness%3F" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F09%2Fspring-boot-on-quarkus-magic-or-madness%2F&amp;#38;linkname=Spring%20Boot%20on%20Quarkus%3A%20Magic%20or%20madness%3F" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F09%2Fspring-boot-on-quarkus-magic-or-madness%2F&amp;#038;title=Spring%20Boot%20on%20Quarkus%3A%20Magic%20or%20madness%3F" data-a2a-url="https://developers.redhat.com/blog/2021/02/09/spring-boot-on-quarkus-magic-or-madness/" data-a2a-title="Spring Boot on Quarkus: Magic or madness?"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/09/spring-boot-on-quarkus-magic-or-madness/"&gt;Spring Boot on Quarkus: Magic or madness?&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Rubsp5_qZac" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Quarkus is a Java stack tailored for OpenJDK HotSpot (or OpenJ9 on zSeries) and GraalVM, crafted from optimized Java libraries and standards. It is a good choice for building highly-scalable applications while using lower amounts of CPU and memory resources than other Java frameworks. These applications can be traditional web applications, serverless applications, or even [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/09/spring-boot-on-quarkus-magic-or-madness/"&gt;Spring Boot on Quarkus: Magic or madness?&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/09/spring-boot-on-quarkus-magic-or-madness/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">855487</post-id><dc:creator>Eric Deandrea</dc:creator><dc:date>2021-02-09T08:00:58Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/09/spring-boot-on-quarkus-magic-or-madness/</feedburner:origLink></entry><entry><title>Deploying Kubernetes Operators with Operator Lifecycle Manager bundles</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Fz4zpPjv0vk/" /><category term="Go" /><category term="Kubernetes" /><category term="Operator" /><category term="OLM bundles" /><category term="operator framework" /><category term="Operator Lifecycle Manager" /><category term="operator-sdk" /><author><name>Jeff McCormick</name></author><id>https://developers.redhat.com/blog/?p=798747</id><updated>2021-02-08T08:00:18Z</updated><published>2021-02-08T08:00:18Z</published><content type="html">&lt;p&gt;This article shows an example of using the &lt;a target="_blank" rel="nofollow" href="https://olm.operatorframework.io/"&gt;Operator Lifecycle Manager&lt;/a&gt; (OLM) bundle deployment architecture to deploy a &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt; or other &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; Operator. You will learn how to use OLM and the &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/"&gt;Operator SDK&lt;/a&gt; (both components of the Kubernetes &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework"&gt;Operator Framework&lt;/a&gt;) together to deploy an Operator.&lt;/p&gt; &lt;h2&gt;About the example&lt;/h2&gt; &lt;p&gt;I tested the Operator Lifecycle Manager example on both an OpenShift 4.6 cluster (via &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt;) and a local Kubernetes &lt;a target="_blank" rel="nofollow" href="https://kind.sigs.k8s.io/"&gt;Kind 1.18&lt;/a&gt; cluster. I used &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/"&gt;Operator SDK 1.0&lt;/a&gt; and OLM 0.15.0 for this example.&lt;/p&gt; &lt;h2&gt;Scaffolding the Operator&lt;/h2&gt; &lt;p&gt;A &lt;em&gt;bundle&lt;/em&gt; is an Operator packaging construct that contains an Operator definition and manifests used to determine how the Operator is deployed onto a Kubernetes cluster. The original OLM package manifest format has migrated to the bundle format.&lt;/p&gt; &lt;p&gt;In this example, we will use &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/"&gt;Operator SDK&lt;/a&gt; 1.0 to generate an Operator bundle and create the Operator for deployment. Enter the following &lt;code&gt;operator-sdk&lt;/code&gt; commands to begin scaffolding the sample Operator:&lt;/p&gt; &lt;pre&gt;$ operator-sdk init --domain=example.com --repo=github.com/example-inc/doo-operator $ operator-sdk create api --group cache --version v1 --kind Doo --resource=true --controller=true &lt;/pre&gt; &lt;h2&gt;Working with container images in Operator SDK&lt;/h2&gt; &lt;p&gt;When &lt;code&gt;operator-sdk&lt;/code&gt; generates or scaffolds an Operator, it does not include any logic about your application. You will need to include information about how to install and manage your application. Like any other Operator, the resulting code is built into a container image. In this example, the Operator image is named &lt;code&gt;quay.io/username/doo-operator:v0.0.1&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Entering the &lt;code&gt;operator-sdk init&lt;/code&gt; command creates a project structure. This command also creates a Makefile that you can use for various build and deployment tasks. Enter the following to build an Operator image using a Makefile:&lt;/p&gt; &lt;pre&gt;$ make docker-build docker-push IMG=quay.io/username/doo-operator:v0.0.1 &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: See the &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/docs/building-operators/golang/"&gt;Operator SDK documentation&lt;/a&gt; for more about building Operators with &lt;code&gt;operator-sdk&lt;/code&gt; and Golang.&lt;/p&gt; &lt;h2&gt;Building an Operator bundle image&lt;/h2&gt; &lt;p&gt;Apart from the Operator image, an &lt;em&gt;operator bundle&lt;/em&gt; is an OLM-prescribed format for holding Operator metadata. The metadata contains everything Kubernetes needs to know to use the Operator, including its custom resource definitions (CRDs), required role-based access and control (RBAC) roles and bindings, dependency tree, and more.&lt;/p&gt; &lt;h3&gt;Generate a bundle&lt;/h3&gt; &lt;p&gt;You can use the &lt;code&gt;operator-sdk&lt;/code&gt;-generated Makefile to create a bundle for your Operator:&lt;/p&gt; &lt;pre&gt;$ make bundle IMG=quay.io/username/doo-operator:v0.0.1 &lt;/pre&gt; &lt;p&gt;This command generates an on-disk set of bundle manifests. Here is an example of the directory structure for a generated bundle:&lt;/p&gt; &lt;pre&gt;bundle ├── manifests │   ├── cache.example.com_dooes.yaml │   ├── doo.clusterserviceversion.yaml │   └── doo-metrics-reader_rbac.authorization.k8s.io_v1beta1_clusterrole.yaml ├── metadata │   └── annotations.yaml └── tests     └── scorecard         └── config.yaml &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;make bundle&lt;/code&gt; command also creates a Dockerfile (&lt;code&gt;bundle.Dockerfile&lt;/code&gt;), which is used to build a &lt;em&gt;bundle image&lt;/em&gt;. The bundle image is an &lt;a target="_blank" rel="nofollow" href="https://github.com/opencontainers/image-spec"&gt;Open Container Initiative&lt;/a&gt; (OCI)-compliant image that holds the generated on-disk bundle manifest and metadata files.&lt;/p&gt; &lt;h3&gt;Create and push the bundle image&lt;/h3&gt; &lt;p&gt;In this example, we&amp;#8217;ll name the Operator bundle image as follows:&lt;/p&gt; &lt;pre&gt;quay.io/username/doo-operator-bundle:v0.0.1 &lt;/pre&gt; &lt;p&gt;To create and push the image, run the following Makefile targets:&lt;/p&gt; &lt;pre&gt;$ make bundle-build BUNDLE_IMG=quay.io/username/doo-operator-bundle:v0.0.1 $ make docker-push IMG=quay.io/username/doo-operator-bundle:v0.0.1 &lt;/pre&gt; &lt;h2&gt;Building the Operator index image&lt;/h2&gt; &lt;p&gt;Another OLM concept is the &lt;em&gt;index image&lt;/em&gt;. This container image serves an application programming interface (API), which describes information about your sample Operator. The index image includes information from your bundle image by running &lt;code&gt;opm&lt;/code&gt;, an Operator registry command:&lt;/p&gt; &lt;pre&gt;$ opm index add --bundles quay.io/username/doo-operator-bundle:v0.0.1 --tag quay.io/username/doo-operator-index:v0.0.1 $ podman push quay.io/username/doo-operator-index:v0.0.1 &lt;/pre&gt; &lt;p&gt;The index image holds an &lt;a target="_blank" rel="nofollow" href="https://www.sqlite.org"&gt;SQLite&lt;/a&gt; database with bundle definitions. It also runs a &lt;a target="_blank" rel="nofollow" href="https://grpc.io/docs/what-is-grpc/core-concepts/"&gt;gRPC&lt;/a&gt; service when the image is executed. The gRPC service lets consumers query the SQLite database about the Operators the index contains.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: You can download the &lt;code&gt;opm&lt;/code&gt; command from the Operator Framework&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-registry"&gt;Operator registry&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Running the bundle index image&lt;/h2&gt; &lt;p&gt;At this point, you should have OLM installed on your Kubernetes cluster. OLM is installed by default on OpenShift clusters. You can use Operator SDK&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/docs/cli/operator-sdk_olm_install/"&gt;olm install&lt;/a&gt; command to install OLM on any other Kubernetes cluster manually.&lt;/p&gt; &lt;p&gt;Once you have an index image, deploy it by creating an OLM &lt;code&gt;CatalogSource&lt;/code&gt; resource. For our sample Operator, we create the &lt;code&gt;CatalogSource&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt;$ cat &amp;#60;&amp;#60;EOF | kubectl create -f - kind: CatalogSource metadata:   name: doo-operator   namespace: operators spec:   sourceType: grpc   image: quay.io/username/doo-operator-index:v0.0.1 EOF &lt;/pre&gt; &lt;p&gt;This &lt;code&gt;CatalogSource&lt;/code&gt; is created in an existing namespace, created by OLM, named &lt;code&gt;operators&lt;/code&gt;. On OpenShift clusters, this namespace is called &lt;code&gt;openshift-operators&lt;/code&gt;. When you create the &lt;code&gt;CatalogSource&lt;/code&gt;, it causes the index image to be executed as a pod. You can view it as follows:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators get pod --selector=olm.catalogSource=doo-operator NAME                                                              READY   STATUS      RESTARTS   AGE doo-operator-79x8z                                                1/1     Running     0          136m &lt;/pre&gt; &lt;p&gt;You can look at the pod&amp;#8217;s log to ensure the image is serving the gRPC API:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators logs pod/doo-operator-79x8z time="2020-10-05T13:17:04Z" level=info msg="Keeping server open for infinite seconds" database=/database/index.db port=50051 time="2020-10-05T13:17:04Z" level=info msg="serving registry" database=/database/index.db port=50051 &lt;/pre&gt; &lt;h2&gt;Deploying the Operator&lt;/h2&gt; &lt;p&gt;We use an OLM &lt;em&gt;subscription&lt;/em&gt; resource to trigger a specific Operator deployment. With the following command, we create a &lt;code&gt;Subscription&lt;/code&gt; that triggers the deployment of our sample Operator:&lt;/p&gt; &lt;pre&gt;$ cat &amp;#60;&amp;#60;EOF | kubectl create -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata:   name: doo-subscription   namespace: operators  spec:   channel: alpha   name: doo   source: doo-operator   sourceNamespace: operators EOF &lt;/pre&gt; &lt;p&gt;Notice that the &lt;code&gt;Subscription&lt;/code&gt; is created in the pre-existing &lt;code&gt;operators&lt;/code&gt; namespace so that OLM will create the sample Operator in that same namespace. (Note, again, that on OpenShift clusters, the namespace is called &lt;code&gt;openshift-operators&lt;/code&gt;.)&lt;/p&gt; &lt;h2&gt;Verifying the Operator&lt;/h2&gt; &lt;p&gt;We can use the following commands to verify the sample Operator is running. Let&amp;#8217;s start by verifying the &lt;code&gt;Subscription&lt;/code&gt; has been created:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators get subscription NAME               PACKAGE   SOURCE         CHANNEL doo-subscription   doo       doo-operator   alpha &lt;/pre&gt; &lt;p&gt;Next, verify the operator CSV has successfully deployed:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators get csv NAME         DISPLAY        VERSION   REPLACES   PHASE doo.v0.0.1   doo-operator   0.0.1                Succeeded &lt;/pre&gt; &lt;p&gt;Finally, verify the Operator is running:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators get pod NAME                                      READY   STATUS    RESTARTS   AGE doo-controller-manager-6c4bdf7db6-jcvpn   2/2     Running   0          10m &lt;/pre&gt; &lt;h2&gt;Testing the Operator&lt;/h2&gt; &lt;p&gt;We can test the sample Operator by creating a &lt;code&gt;CustomResource&lt;/code&gt; that the sample Operator is watching.&lt;br /&gt; Create the &lt;code&gt;CustomResource&lt;/code&gt; in the &lt;code&gt;default&lt;/code&gt; namespace as follows:&lt;/p&gt; &lt;pre&gt;$ cat &amp;#60;&amp;#60;EOF | kubectl -n default create -f - {            "apiVersion": "cache.example.com/v1",            "kind": "Doo",            "metadata": {              "name": "doo-sample"            },            "spec": {              "foo": "bar"            }          }  EOF &lt;/pre&gt; &lt;p&gt;Your sample Operator should respond to the creation of the &lt;code&gt;CustomResource&lt;/code&gt; by checking the sample Operator log:&lt;/p&gt; &lt;pre&gt;$ kubectl -n operators logs pod/doo-controller-manager-6c4bdf7db6-jcvpn -c manager 2020-10-05T13:29:52.175Z DEBUG controller Successfully Reconciled{"reconcilerGroup": "cache.example.com", "reconcilerKind": "Doo", "controller": "doo", "name": "doo-sample", "namespace": "default"} &lt;/pre&gt; &lt;h2&gt;Create a unique namespace and OperatorGroup&lt;/h2&gt; &lt;p&gt;Examples so far used namespaces that were pre-created when you installed OLM. In some cases, you might want to isolate your Operator deployments into a namespace that you create. For this, you will need to create a unique namespace and &lt;code&gt;OperatorGroup&lt;/code&gt;. My namespace for this example is &lt;code&gt;jeff-operators&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ kubectl create namespace jeff-operators $ cat &amp;#60;&amp;#60;EOF | kubectl create -f - apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata:   name: jeff-operators   namespace: jeff-operators status:   lastUpdated: "2020-10-07T13:44:54Z"   namespaces:   - "" EOF &lt;/pre&gt; &lt;p&gt;Note that you create the unique namespace &lt;em&gt;before&lt;/em&gt; creating your &lt;code&gt;CatalogSource&lt;/code&gt; and subscription. You will need to create these components in the namespace that contains your &lt;code&gt;OperatorGroup&lt;/code&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: For more about &lt;code&gt;OperatorGroup&lt;/code&gt;s, see &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-lifecycle-manager/blob/master/doc/design/operatorgroups.md"&gt;Operator Multitenancy with OperatorGroups&lt;/a&gt; in the OLM GitHub repository.&lt;/p&gt; &lt;h2&gt;OLM bundle automation in Operator SDK&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;operator-sdk&lt;/code&gt; includes a new &lt;code&gt;run bundle&lt;/code&gt; command that uses a temporary bundle index image for many of the steps described in this article. The &lt;code&gt;run bundle&lt;/code&gt; command will be useful for developers needing to test their Operators using the OLM bundle architecture.  Here&amp;#8217;s an example of the command:&lt;/p&gt; &lt;pre&gt;$ operator-sdk run bundle quay.io/username/doo-operator-bundle:v0.0.1 &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The Operator Lifecycle Manager&amp;#8217;s bundle architecture is an advanced mechanism for describing, publishing, and deploying Operators on Kubernetes clusters. This article introduced you to using OLM&amp;#8217;s bundle deployment architecture and the Operator SDK to deploy a Kubernetes Operator.&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;See the following resources to learn more about OLM and the Operator Framework:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Visit the &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-lifecycle-manager"&gt;OLM GitHub repository&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://olm.operatorframework.io"&gt;OLM homepage&lt;/a&gt; for more about using the Operator Lifecycle Manager to install, manage, and upgrade Operators and their dependencies in a Kubernetes cluster.&lt;/li&gt; &lt;li&gt;Learn more about &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-lifecycle-manager/blob/master/doc/design/operatorgroups.md"&gt;Operator multitenancy with OperatorGroups&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;See the &lt;a target="_blank" rel="nofollow" href="https://sdk.operatorframework.io/docs/building-operators/golang/"&gt;Guide to building a Golang based Operator using Operator SDK&lt;/a&gt; for a quickstart for creating Go-based Operators and more.&lt;/li&gt; &lt;li&gt;Find out more about &lt;a target="_blank" rel="nofollow" href="https://www.sqlite.org/index.html"&gt;SQLite&lt;/a&gt; and the &lt;a target="_blank" rel="nofollow" href="https://sqlitebrowser.org/"&gt;Database Browser for SQLite&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Get started with &lt;a target="_blank" rel="nofollow" href="https://grpc.io/"&gt;gRPC&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://github.com/fullstorydev/grpcurl"&gt;using the grpcurl command-line tool&lt;/a&gt; to interact with gRPC servers.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;Thanks to Red Hat engineers Eric Stroczynski and Jesus Rodriguez for reviewing this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#38;linkname=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F08%2Fdeploying-kubernetes-operators-with-operator-lifecycle-manager-bundles%2F&amp;#038;title=Deploying%20Kubernetes%20Operators%20with%20Operator%20Lifecycle%20Manager%20bundles" data-a2a-url="https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/" data-a2a-title="Deploying Kubernetes Operators with Operator Lifecycle Manager bundles"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/"&gt;Deploying Kubernetes Operators with Operator Lifecycle Manager bundles&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Fz4zpPjv0vk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article shows an example of using the Operator Lifecycle Manager (OLM) bundle deployment architecture to deploy a Red Hat OpenShift or other Kubernetes Operator. You will learn how to use OLM and the Operator SDK (both components of the Kubernetes Operator Framework) together to deploy an Operator. About the example I tested the Operator Lifecycle [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/"&gt;Deploying Kubernetes Operators with Operator Lifecycle Manager bundles&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">798747</post-id><dc:creator>Jeff McCormick</dc:creator><dc:date>2021-02-08T08:00:18Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles/</feedburner:origLink></entry><entry><title type="html">The After Open Source Era Has Started</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Y3vVQPN_GKk/the-after-open-source-era-has-started.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2021/02/the-after-open-source-era-has-started.html</id><updated>2021-02-07T08:32:00Z</updated><content type="html">Open source is the current norm for developer collaboration and customer adoption in software. It is the foundation that enabled unicorns and cloud providers to build their services from the ground up. But that wasn’t always the case with open source, and it is changing and evolving again. Open Source Eras and relative adoption trend lines In this post, I will look at open source evolution broadly, try to analyze what are some of the triggers and enablers for the change, and where it might be heading next. Let’s start with the main open software development eras by summarizing the main trends and then focus on the big picture with an attempt to predict the future. FREE SOFTWARE (1980) The term “free software” is attributed to Richard Stallman around the 1980s for using it for the . During these early days of computing, Richard started the GNU project in an effort to cultivate collaboration among the early hacker community and create a freedom-respecting operating system. He campaigns for software to be distributed in a manner such that its users receive the freedoms to use, study, distribute, and modify that software. This era set the origins of open source and more importantly the free software licenses (such as GPL) that flourish later. At the time, the main software creators in the open were the individual hackers and in their view of the world, the software had to be free as speech and remain so. Free software grew because personal computers became more widely available to these hackers and they used CDs, floppy disks, and the early internet to distribute software and spread their ideology. In this pre-internet era, manual distributions of software, supporting documentation, consulting services (installation, development), were some of the popular monetization methods. OPEN SOURCE SOFTWARE (2000) The term "open source" was used by a group of people from the free-software movement around 2000. The motivation for this new term was to free itself from the ideological and confrontational connotations of the term "free software" and make it more appealing for the business world. The supporters of the open source movement stress the subtle difference from free software where free software requires any changes to be submitted to the original maker for redistribution, and any derivative software must also be distributed as free software. This new term set the beginning of a new movement and the forming of to educate and advance open source culture. The open source movement allowed smaller companies to play a more significant role in the software economy by giving them access to the software needed to compete in the global market. Before that, it was the larger corporations, the producers of the networks and hardware who had the power. Open source sparked from the early hackers community but grew rapidly into open source businesses, enabled by software foundations, the internet, and the wider adoption of open source by companies of all sizes. The primary monetization mechanism for the open source software is through support and the open core models where additional accompanying value is created around the core open source project. While this open core (enabled by permissive licenses such as MIT, Apache) allows everybody to benefit from it, it is also its Achilles' heel as we will see next. SHARED SOURCE SOFTWARE (2020) Open source licenses give more freedom to the users, but they don’t give many advantages to the producers of the software. Many small projects with a handful of maintainers create huge economic value which ends up captured by other companies with better operational capabilities to monetize. This leads the maintainers of these projects to remain below the poverty line. Other companies hire open source maintainers as full-time employers and bet their company existence and brand into the success of their open source project. Yet they got disrupted and threatened by even larger hyperscale SaaS providers who have the scale to capture the economical value more efficiently and faster from the same projects. This new economic reality started forcing individual maintainers and small companies to move their software away from business-friendly open source to other free software inspired derivative licenses and pursue dual-licensing models. This new family of licenses is not proprietary, but they don’t fit the open source definition either as they protect the trademark owner from the competition by discriminating against certain ways of software distributions such as SaaS. This transition of new and existing open source projects to non-open source licenses indicates the start of a new era. Keeping the source partially open is primarily for marketing and user adoption purposes rather than collaborative development and keeping software useful for everybody. This shared source software era is triggered by the existential threat of not being able to offer the software in a way demanded by consumers (as a SaaS) and efficiently capture economical value by the creators whether they are individual contributors or large companies with an open source business model. Open source software eras and main characteristics Protected by these new licenses, the enablers for the modern-day independent hackers are the powerful online services that allow them to offer good quality software through globally available automation tools based on git, build tools, software scanning, and distribution services, etc. These hackers can build enough critical mass of supporters through social media and are able to capture economical value through services such as Github sponsors, Patreon, Tidelift, and . The other group, the disrupted open source companies are transitioning to the SaaS based distribution of software as vertical cloud services on top of the hybrid cloud infrastructure to compete with cloud providers. This allows the creators of the software to offer their service on multiple clouds and at the same time align with the way users prefer to consume software, which is as a service. WHAT WILL SOFTWARE AFTER OPEN SOURCE LOOK LIKE? The start of a new trend doesn’t indicate the end of the existing eras, but a new addition to the mix. Free and open source software will continue growing at a huge pace. At the same time, I believe we will see an acceleration of the trend towards the so-called shared source and source available licenses too. This will double down on the dual-licensing of smaller library projects by individual developers and the SaaS-based distribution of bigger projects. The open core and open source models will remain here, but the open core of the projects will get smaller and smaller, practically useless for the competitors. We will see projects starting as open source during bootstrapping and initial adoption phases, and then transition to source available licenses when threatened by more operationally mature competitors. Unfortunately, this initial phase of uncertainty and adaptation in the shared source era will limit collaboration among competitors and demonstrate the importance of open governance and open funding through neutral software foundations or decentralized technologies. Then we will see cycles repeating and independent hackers flourish again, innovating as in the free software era. But this time they will be better equipped with better infrastructure to support their livelihood as independent small businesses of one. They will start projects in the open to scratch their itch, but quickly turn them into businesses or let them die. They will be less ideological, and more practical. These independent hackers will not need to be part of the traditional horizontal software companies that bundle engineering, marketing, sales, support, education, etc to be successful in the software business. Instead, they will be able to consume unbundled vertical online services and deliver enterprise-grade software. We will see a rise in the tools and platforms that offer reliable project governance without joining a foundation or consortium. Independent software builders can use decentralized , their projects, and customize the through on-chain community voting. The economical and governance aspects of the projects will be merged with the source code and licenses into a holistic entity enabled by blockchain technology and create opportunities for individual hackers to create million-dollar companies. The infrastructure for independent techies will not be only for the software builders but for the whole ecosystem. Creating software is not enough, it has to go through the full pipeline of budgeting, building, marketing, hosting, sales, support in order to grow and remain sustainable. Speculators will put money into project tokens to help bootstrap projects and gain returns. Developers will build. Indies will create niche services complementing larger projects. Subject matter experts will provide consulting services and online training, and bounty hackers will hunt for ad-hoc work. Sometimes all of it will be driven by a single person, and sometimes a whole decentralized ecosystem forming around a project without the dominance of a central business entity. This will take a generation of software builders... CONCLUSION At the beginning of the open source era, Eric S. Raymond described a decentralized software development process called . This era proved that the bazaar is the superior software development model. But at the same time, this era also showed us the limitations and the narrow mindedness of this model when it is not accompanied by a . The next era will improve on the same decentralized development principles by incorporating decentralized monetization and governance too. This will take us the full cycle of Decentralized and Sustainable Open Software nirvana. If you like my explorations of opensource, blockchain, monetization, sing up to my or follow me on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Y3vVQPN_GKk" height="1" width="1" alt=""/&gt;</content><dc:creator>Unknown</dc:creator><feedburner:origLink>http://www.ofbizian.com/2021/02/the-after-open-source-era-has-started.html</feedburner:origLink></entry><entry><title type="html">Eclipse Vert.x 4.0.2 released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-fYwOHvjKE4/eclipse-vert-x-4-0-2" /><author><name>Julien Viet</name></author><id>https://vertx.io/eclipse-vert-x-4-0-2</id><updated>2021-02-05T00:00:00Z</updated><content type="html">Eclipse Vert.x version 4.0.2 has just been released. It fixes quite a few bugs that have been reported by the community.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-fYwOHvjKE4" height="1" width="1" alt=""/&gt;</content><dc:creator>Julien Viet</dc:creator><feedburner:origLink>https://vertx.io/eclipse-vert-x-4-0-2</feedburner:origLink></entry><entry><title>A guide for using CentOS Project code</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/p39_GzFB7Us/" /><category term="Linux" /><category term="Open source" /><category term="CentOS" /><category term="CentOS Stream" /><author><name>Brian Exelbierd</name></author><id>https://developers.redhat.com/blog/?p=866107</id><updated>2021-02-03T17:32:53Z</updated><published>2021-02-03T17:32:53Z</published><content type="html">&lt;p&gt;Many people have approached us asking about how we will publish the CentOS sources and if we are making changes because of &lt;a target="_blank" rel="nofollow" href="https://blog.centos.org/2020/12/future-is-centos-stream/"&gt;the announcements&lt;/a&gt; on 8 December 2020 that we are focusing on CentOS Stream. In short, we are not making any changes to this process.&lt;/p&gt; &lt;p&gt;The CentOS sources will still be published to git.centos.org in repositories that contain dist-git style sources. If you are looking for public access to the code, this will be the place to go.&lt;/p&gt; &lt;p&gt;If you’re considering using this code in your own project &amp;#8211; especially if that project has the goal of producing a Linux distribution &amp;#8211; we’ve put together some guidance to help you comply with the Red Hat services agreements and trademark guidelines. This guidance is not exhaustive.&lt;/p&gt; &lt;p&gt;In the spirit of community collaboration, we offer a list of do’s and don’ts below.&lt;/p&gt; &lt;h1&gt;Do&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Get your source code from upstream or git.centos.org and follow the &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/about/trademark-guidelines-and-policies"&gt;Red Hat trademark guidelines&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Clearly describe your distribution as something you made, not Red Hat.  You may wish to say you started with source from a specific location, such as “modified and built from source code taken from git.centos.org.”&lt;/li&gt; &lt;li&gt;Prominently include the following disclaimer when publishing or promoting your distribution: “Red Hat and CentOS are trademarks or registered trademarks of Red Hat, Inc. or its subsidiaries in the United States and other countries. We are not affiliated with, endorsed by or sponsored by Red Hat or the CentOS Project.”&lt;/li&gt; &lt;li&gt;Comply with the GPL and all the other open source licenses applicable to your build.&lt;/li&gt; &lt;li&gt;If you have an agreement with Red Hat, such as being a member of the Red Hat Developer program or working for a Red Hat customer or partner, review the terms of the agreement so you know your obligations  (&lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/about/agreements"&gt;https://www.redhat.com/en/about/agreements&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/wapps/tnc/viewterms/72ce03fd-1564-41f3-9707-a09747625585?extIdCarryOver=true&amp;#38;sc_cid=701f2000001Css0AAC"&gt;individual developer program&lt;/a&gt;, respectively).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h1&gt;Don’t&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Use Red Hat Subscription Services to create or support your project.&lt;/li&gt; &lt;li&gt;Use any Red Hat trademarks, including the Red Hat logo, in the project,  your distribution, or in your promotion and marketing of the project, other than as permitted under &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/about/trademark-guidelines-and-policies"&gt;Red Hat’s trademark guidelines&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#38;linkname=A%20guide%20for%20using%20CentOS%20Project%20code" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fa-guide-for-using-centos-project-code%2F&amp;#038;title=A%20guide%20for%20using%20CentOS%20Project%20code" data-a2a-url="https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/" data-a2a-title="A guide for using CentOS Project code"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/"&gt;A guide for using CentOS Project code&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/p39_GzFB7Us" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Many people have approached us asking about how we will publish the CentOS sources and if we are making changes because of the announcements on 8 December 2020 that we are focusing on CentOS Stream. In short, we are not making any changes to this process. The CentOS sources will still be published to git.centos.org [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/"&gt;A guide for using CentOS Project code&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">866107</post-id><dc:creator>Brian Exelbierd</dc:creator><dc:date>2021-02-03T17:32:53Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/03/a-guide-for-using-centos-project-code/</feedburner:origLink></entry><entry><title>Deliver your applications to edge and IoT devices in rootless containers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/yzTCTOw-I0A/" /><category term="Automation" /><category term="CI/CD" /><category term="Containers" /><category term="Internet of Things" /><category term="Kubernetes" /><category term="Ansible" /><category term="edge applications" /><category term="iot edge" /><category term="Podman" /><author><name>Ilkka Tengvall</name></author><id>https://developers.redhat.com/blog/?p=851907</id><updated>2021-02-03T08:00:37Z</updated><published>2021-02-03T08:00:37Z</published><content type="html">&lt;p&gt;Applications are often developed, tested, and delivered in &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; is a great platform for that purpose. Sometimes, however, the target machine is much smaller than a &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; cluster. It might be an embedded server, industry PC hardware, or a single server.&lt;br /&gt; &lt;img class=" alignright wp-image-852007 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2021/01/systemd-podman-ansible.png" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/systemd-podman-ansible.png" alt="Image: Systemd + Podman + Ansible." width="291" height="69" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/systemd-podman-ansible.png 672w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/systemd-podman-ansible-300x71.png 300w" sizes="(max-width: 291px) 100vw, 291px" /&gt;&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s say the target machine was a &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) &lt;a href="https://developers.redhat.com/topics/edge-computing"&gt;edge server&lt;/a&gt;? How would you automate your container to run in that environment? What if you had &lt;i&gt;thousands of such devices&lt;/i&gt;? In that case, you would want a fully automated rootless container for security. But how do you automate rootless containers?&lt;/p&gt; &lt;p&gt;In this article, you&amp;#8217;ll learn how to use systemd, &lt;a href="https://developers.redhat.com/articles/podman-next-generation-linux-container-tools"&gt;Podman&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Red Hat Ansible Automation&lt;/a&gt; to automate and push software as containers to small-scale edge and &lt;a href="https://developers.redhat.com/blog/category/iot/"&gt;Internet-of-Things&lt;/a&gt; (IoT) gateway devices.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: While I have not included &lt;a target="_blank" rel="nofollow" href="https://www.ansible.com/products/tower"&gt;Red Hat Ansible Tower&lt;/a&gt; in the demonstration, integrating it would be the next logical next step.&lt;/p&gt; &lt;h2&gt;Why rootless containers?&lt;/h2&gt; &lt;p&gt;Why should you use &lt;a href="https://developers.redhat.com/blog/2020/09/25/rootless-containers-with-podman-the-basics/"&gt;rootless containers&lt;/a&gt; to deliver applications to edge and IoT boxes? Well, it&amp;#8217;s another layer of security. Even if an evil blackhat manages to break into your container, find a security hole, and punch through your Security-Enhanced Linux (SELinux) module, the rootless container ensures they won&amp;#8217;t have privileges in the system.&lt;/p&gt; &lt;p&gt;As a developer, you also don’t necessarily need root privileges in the target device. Your team could deliver the application to end devices as containers, while only admins have the privileges to manage the boxes.&lt;/p&gt; &lt;h2&gt;Set up the development environment&lt;/h2&gt; &lt;p&gt;I’ve previously written about &lt;a target="_blank" rel="nofollow" href="https://redhatnordicssa.github.io/ansible-podman-containers-1"&gt;automating Podman containers with Ansible&lt;/a&gt;, but I&amp;#8217;ve only recently added the rootless option to my Ansible role. We’ll use &lt;a target="_blank" rel="nofollow" href="https://galaxy.ansible.com/ikke_t/podman_container_systemd"&gt;the updated Ansible role&lt;/a&gt; and an &lt;a target="_blank" rel="nofollow" href="https://github.com/ansible-collections/community.grafana"&gt;Ansible module for Grafana&lt;/a&gt; for this demonstration.&lt;/p&gt; &lt;p&gt;We&amp;#8217;ll set up Grafana with a dummy dashboard and test users for an RHEL edge server to get started. I have tested the example also on a Fedora IoT distribution and a standard RHEL server.&lt;/p&gt; &lt;p&gt;Our end goal is to create persistent containers using systemd, Podman, and Ansible Tower, where the containers have user-only privileges. In this case, systemd manages the user processes, but any Docker container would work the same. Figure 1 shows how these components would work together.&lt;/p&gt; &lt;div id="attachment_851967" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user.png"&gt;&lt;img aria-describedby="caption-attachment-851967" class=" alignright wp-image-851967 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-1024x640.png" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-1024x640.png" alt="A flow diagram for the example." width="640" height="400" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-1024x640.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-300x188.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/podman-user-768x480.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851967" class="wp-caption-text"&gt;Figure 1: Creating persistent containers with systemd, Podman, and Ansible Tower.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the next sections, we&amp;#8217;ll set up and configure this automation.&lt;/p&gt; &lt;h2&gt;Systemd changes in Ansible&lt;/h2&gt; &lt;p&gt;First, let&amp;#8217;s look at what needs to change to make the &lt;a target="_blank" rel="nofollow" href="https://galaxy.ansible.com/ikke_t/podman_container_systemd"&gt;podman_container_systemd&lt;/a&gt; role work in user mode. We&amp;#8217;ll also look at the changes needed for Fedora CoreOS and similar servers that are intended to run only containers.&lt;/p&gt; &lt;h3&gt;User systemd services&lt;/h3&gt; &lt;p&gt;The first thing we&amp;#8217;ll do is move all of the service files into the user&amp;#8217;s home directory instead of the &lt;code&gt;/etc/systemd/system&lt;/code&gt; or &lt;code&gt;/usr/lib/systemd/system&lt;/code&gt; system config directories. We could technically use the &lt;code&gt;/usr/lib/systemd/user&lt;/code&gt;directory, but we want the service files to be private to the user. This way, anyone on the application team can modify them as a regular user if needed.&lt;/p&gt; &lt;p&gt;Here’s the &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L12"&gt;configuration code for this step&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;   - name: set systemd dir if user is not root      set_fact:        service_files_dir: "{{ user_info.home }}/.config/systemd/user"         systemd_scope: user      changed_when: false     - name: ensure systemd files directory exists if user not root      file:         path: "{{ service_files_dir }}"        state: directory        owner: "{{ container_run_as_user }}"        group: "{{ container_run_as_group }}" &lt;/pre&gt; &lt;h3&gt;Configure a persistent D-BUS session&lt;/h3&gt; &lt;p&gt;The biggest hurdle for me was understanding how a service user gets a &lt;a target="_blank" rel="nofollow" href="https://www.freedesktop.org/wiki/Software/dbus/"&gt;D-BUS session&lt;/a&gt;, which remains available over boots even if the user never logs in. Additionally, systemd must be able to control the user&amp;#8217;s Podman session. We can handle these requirements by setting up a &lt;a target="_blank" rel="nofollow" href="https://www.freedesktop.org/software/systemd/man/loginctl.html"&gt;lingering session&lt;/a&gt; for the user, which activates &lt;code&gt;dbus&lt;/code&gt; for a given user at boot. Here&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L159"&gt;how to set up the lingering session&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; - name: Check if user is lingering    stat:      path: "/var/lib/systemd/linger/{{ container_run_as_user }}"    register: user_lingering    when: container_run_as_user != "root"   - name: Enable lingering is needed    command: "loginctl enable-linger {{ container_run_as_user }}"    when:      - container_run_as_user != "root"      - not user_lingering.stat.exists &lt;/pre&gt; &lt;p&gt;Next, we need to ensure that the systemd commands are &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L33"&gt;executed in user scope&lt;/a&gt;. Because we don’t log in as the target user, but as a privileged Ansible user, we will set an environment variable for &lt;code&gt;xdg_runtime_dir&lt;/code&gt;. We can use this variable to find the user’s lingering &lt;code&gt;dbus&lt;/code&gt; session later. Here is how to &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L33"&gt;set systemd&amp;#8217;s scope to user&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;- name: set systemd runtime dir  set_fact:    xdg_runtime_dir: "/run/user/{{ container_run_as_uid.stdout }}"  changed_when: false - name: set systemd scope to system if needed  set_fact:    systemd_scope: system    service_files_dir: '/etc/systemd/system'    xdg_runtime_dir: "/run/user/{{ container_run_as_uid.stdout }}"  when: container_run_as_user == "root"  changed_when: false &lt;/pre&gt; &lt;h2&gt;Set the default target&lt;/h2&gt; &lt;p&gt;We also need to change the systemd session file to the default target when it&amp;#8217;s run in rootless. Here&amp;#8217;s the &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/templates/systemd-service-single.j2#L26"&gt;configuration for the default target&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;[Install] {% if container_run_as_user == 'root' %} WantedBy=multi-user.target {% endif %} {% if container_run_as_user != 'root' %} WantedBy=default.target {% endif %} &lt;/pre&gt; &lt;h3&gt;User systemd commands&lt;/h3&gt; &lt;p&gt;We&amp;#8217;ve set all the required variables. Next, we need to &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/handlers/main.yml#L12"&gt;tell Ansible to use the D-BUS session&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;- name: start service  become: true  become_user: "{{ container_run_as_user }}"  environment:    XDG_RUNTIME_DIR: "{{ xdg_runtime_dir }}"  systemd:    name: "{{ service_name }}"    scope: "{{ systemd_scope }}"    state: started &lt;/pre&gt; &lt;p&gt;Note that we switch to a given user and set the runtime directory to catch the D-BUS. Also, the scope is set to &lt;code&gt;user&lt;/code&gt; instead of &lt;code&gt;system&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;RPM-OSTREE package handling&lt;/h3&gt; &lt;p&gt;For my own purposes, I want to run these containers in minimal, Fedora CoreOS-based machines. Strangely, Ansible doesn’t have a proper package module for this setup. So, I used the following &lt;a target="_blank" rel="nofollow" href="https://github.com/ikke-t/podman-container-systemd/blob/9a0bf79a47b569050e09dcfb3a367dffbf39b4d8/tasks/main.yml#L227"&gt;workaround for checking and installing packages&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;- name: ensure firewalld is installed (on fedora-iot)    tags: firewall    command: &amp;#62;-      rpm-ostree install --idempotent --unchanged-exit-77      --allow-inactive firewalld    register: ostree    failed_when: not ( ostree.rc == 77 or ostree.rc == 0 )    changed_when: ostree.rc != 77    when: ansible_pkg_mgr == "atomic_container"  - name: reboot if new stuff was installed    reboot:      reboot_timeout: 300    when:      - ansible_pkg_mgr == "atomic_container"      - ostree.rc != 77 &lt;/pre&gt; &lt;p&gt;You might not want to install anything there, but this configuration handles the required reboot if you do. It made sense for using Fedora CoreOS in an IoT system.&lt;/p&gt; &lt;p&gt;At this point, we are pretty much done with the changes.&lt;/p&gt; &lt;h2&gt;Try it out&lt;/h2&gt; &lt;p&gt;In case you want to try this yourself (and why wouldn’t you?), I will share the commands to run this example in your own environment. I used RHEL 8 on my laptop and an RHEL edge server as the target virtual machine. If you don&amp;#8217;t have access to RHEL edge, you can also use Feroda-IoT as the target.&lt;/p&gt; &lt;p&gt;I like to keep everything related to tasks in one directory, including the required collections and roles. I&amp;#8217;ve set all of this up, including the requirements files, in the example project repository. All you need to do is get it:&lt;/p&gt; &lt;pre&gt;sudo dnf install ansible git clone https://github.com/ikke-t/ansible-podman-sample.git cd ansible-podman-sample &lt;/pre&gt; &lt;p&gt;Then, install the role and collection dependencies:&lt;/p&gt; &lt;pre&gt;ansible-galaxy collection install -r collections/requirements.yml -p collections ansible-galaxy role install -r roles/requirements.yml -p roles &lt;/pre&gt; &lt;p&gt;And run the playbook:&lt;/p&gt; &lt;pre&gt;ln -s roles/ikke_t.grafana_podman/tests/test.yml run-container-grafana-podman.yml ansible-playbook -i edge, -u cloud-user -b \  -e container_state=running \  -e ansible_pkg_mgr=atomic_container \  run-container-grafana-podman.yml &lt;/pre&gt; &lt;p&gt;You will need to change the following settings for your system:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;You only need the &lt;code&gt;ansible_pkg_mgr&lt;/code&gt; setting if &lt;a target="_blank" rel="nofollow" href="https://github.com/ansible/ansible/issues/73084"&gt;the target is an RHEL edge server&lt;/a&gt;; otherwise, you can remove this line.&lt;/li&gt; &lt;li&gt;&lt;code&gt;edge&lt;/code&gt; is my VM server&amp;#8217;s SSH address.&lt;/li&gt; &lt;li&gt;&lt;code&gt;cloud-user&lt;/code&gt; is the &lt;code&gt;sudo&lt;/code&gt;-privileged Ansible user in the target VM.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let it run for a minute, and &amp;#8230; drumroll &amp;#8230; &lt;em&gt;ta-dah!&lt;/em&gt; As shown in Figure 2, we have our Grafana dashboard running in a user session as a container (http://your_vm:3000).&lt;/p&gt; &lt;div id="attachment_851937" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-851937" class=" alignright wp-image-851937 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard.png" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard-300x177.png" alt="The Grafana dashboard running in a user session." width="600" height="355" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard-300x177.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard-768x454.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-dashboard.png 827w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-851937" class="wp-caption-text"&gt;Figure 2: A simple streaming example in the Grafana dashboard.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 3 shows the test users pushed over the API using the Ansible Grafana collection.&lt;/p&gt; &lt;div id="attachment_851947" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-851947" class=" alignright wp-image-851947 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users.png" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users.png" alt="The Grafana dashboard showing an admin, test-admin, and test-user and their roles." width="600" height="355" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users.png 827w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users-300x177.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/grafana-users-768x454.png 768w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-851947" class="wp-caption-text"&gt;Figure 3: Admin and test users in the Grafana dashboard.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Debugging locally in the target&lt;/h2&gt; &lt;p&gt;We are running the containers as a user, and this Ansible role places them under the user context of systemd.  To use systemd as a given user,  you need to set up a D-BUS-related environment variable. However, the user does not have login credentials, so you need to switch manually to the user using &lt;code&gt;su&lt;/code&gt;. (Note that &lt;code&gt;sudo&lt;/code&gt; won&amp;#8217;t work because the original user ID would show your &lt;code&gt;ssh&lt;/code&gt; user ID.)&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s the command to switch manually to the user:&lt;/p&gt; &lt;pre&gt;su - root su - grafana export XDG_RUNTIME_DIR=/run/user/$UID &lt;/pre&gt; &lt;p&gt;After setting &lt;code&gt;XDG_RUNTIME_DIR&lt;/code&gt; you will be able to use the &lt;code&gt;systemd --user&lt;/code&gt; or &lt;code&gt;journalctl --user&lt;/code&gt; commands to investigate your systemd services set for the container:&lt;/p&gt; &lt;pre&gt;[cloud-user@edge ~]$ su - Password: Last login: Thu Dec 31 13:03:43 EET 2020 on pts/2 [root@edge ~]# su - grafana Last login: Thu Dec 31 13:04:41 EET 2020 on pts/1 (failed reverse-i-search)`export': ^C [grafana@edge ~]$ export XDG_RUNTIME_DIR=/run/user/$UID [grafana@edge ~]$ [grafana@edge ~]$ systemctl --user status grafana-container-pod-grafana.service grafana-container-pod-grafana.service - grafana Podman Container   Loaded: loaded (/var/home/grafana/.config/systemd/user/grafana-container-pod-grafana.service; enabled; ve&amp;#62;   Active: active (running) since Thu 2020-12-31 13:06:35 EET; 29min ago  Process: 1122 ExecStartPre=/usr/bin/rm -f /tmp/grafana-container-pod-grafana.service-pid /tmp/grafana-cont&amp;#62; Main PID: 1126 (podman)   CGroup: /user.slice/user-1002.slice/user@1002.service/grafana-container-pod-grafana.service           ├─1126 /usr/bin/podman run --name grafana --rm -p 3000:3000/tcp -e GF_INSTALL_PLUGINS=flant-statu&amp;#62;           ├─1158 /usr/bin/podman run --name grafana --rm -p 3000:3000/tcp -e GF_INSTALL_PLUGINS=flant-statu&amp;#62;           ├─1167 /usr/bin/podman           ├─1200 /usr/bin/slirp4netns --disable-host-loopback --mtu 65520 --enable-sandbox --enable-seccomp&amp;#62;           ├─1206 /usr/bin/fuse-overlayfs -o lowerdir=/var/home/grafana/.local/share/containers/storage/over&amp;#62;           ├─1214 containers-rootlessport           ├─1227 containers-rootlessport-child           ├─1240 /usr/bin/conmon --api-version 1 -c 2675941bf4743ff26860ff2e84ceaaae78f2fcfbe3fef218e0cfee9&amp;#62;           └─2675941bf4743ff26860ff2e84ceaaae78f2fcfbe3fef218e0cfee914aa96b37             └─1251 grafana-server --homepath=/usr/share/grafana --config=/etc/grafana/grafana.ini --packagi&amp;#62; [grafana@edge ~]$ podman ps CONTAINER ID  IMAGE                             COMMAND  CREATED         STATUS             PORTS                   NAMES 2675941bf474  docker.io/grafana/grafana:latest           29 minutes ago  Up 29 minutes ago  0.0.0.0:3000-&amp;#62;3000/tcp  grafana&lt;/pre&gt; &lt;h2&gt;Cleanup (nuke it)&lt;/h2&gt; &lt;p&gt;You&amp;#8217;ve seen how automating rootless Podman containers using Ansible works; now it’s time to clean it all up. Beware that the “&lt;code&gt;nuke=true&lt;/code&gt;” option removes both the Grafana user and the data. Before using this option, make sure you&amp;#8217;ve stored any data you don&amp;#8217;t want to lose. Note, again, that you need to remove the &lt;code&gt;pkg_mgr&lt;/code&gt; if you are not working on an RHEL edge target:&lt;/p&gt; &lt;pre&gt;ansible-playbook -i edge, -u cloud-user -b \  -e container_state=absent \  -e ansible_pkg_mgr=atomic_container \  -e nuke=true \   run-container-grafana-podman.yml &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Podman and systemd work well for running containers in small setups where Kubernetes would be overkill. Ansible is a robust way to create such a setup. Sometimes, as I&amp;#8217;ve shown here, you don’t even need backups because the target is super easy for Ansible to create from scratch, including the application installation and configurations. It also doesn&amp;#8217;t matter if you have one or thousands of machines at the edge; the setup is basically the same. Remember how we configured Grafana over the API and config file? Consider which is better for your application.&lt;/p&gt; &lt;p&gt;By the way, how about updating the application at the edge? In my example, I set up a Podman container tag to periodically poll for new versions of the container. If you &lt;a target="_blank" rel="nofollow" href="http://docs.podman.io/en/latest/markdown/podman-auto-update.1.html"&gt;enable that service&lt;/a&gt;, you only need to push a new version of the container to the registry at the end of a successful &lt;a href="https://developers.redhat.com/courses/middleware/openshift-pipelines"&gt;CI/CD pipeline in Red Hat OpenShift&lt;/a&gt;. Happy containerizing!&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;See the following to learn more about Podman and systemd:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The Podman documentation includes the &lt;a target="_blank" rel="nofollow" href="http://docs.podman.io/en/latest/markdown/podman-generate-systemd.1.html#:~:text=DESCRIPTION,units%20on%20the%20remote%20system."&gt;podman-generate-systemd&lt;/a&gt; man page.&lt;/li&gt; &lt;li&gt;Learn more about &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/sysadmin/podman-shareable-systemd-services"&gt;running containers with Podman and shareable systemd services&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Learn about &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/sysadmin/improved-systemd-podman"&gt;improved integration with systemd&lt;/a&gt; in Podman 2.0.&lt;/li&gt; &lt;li&gt;Use the &lt;a target="_blank" rel="nofollow" href="http://docs.podman.io/en/latest/markdown/podman-auto-update.1.html"&gt;podman-auto-update&lt;/a&gt; command to auto-update containers according to their auto-update policy.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#38;linkname=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fdeliver-your-applications-to-edge-and-iot-devices-in-rootless-containers%2F&amp;#038;title=Deliver%20your%20applications%20to%20edge%20and%20IoT%20devices%20in%20rootless%20containers" data-a2a-url="https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/" data-a2a-title="Deliver your applications to edge and IoT devices in rootless containers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/"&gt;Deliver your applications to edge and IoT devices in rootless containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/yzTCTOw-I0A" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Applications are often developed, tested, and delivered in containers, and Red Hat OpenShift is a great platform for that purpose. Sometimes, however, the target machine is much smaller than a Kubernetes cluster. It might be an embedded server, industry PC hardware, or a single server. Let&amp;#8217;s say the target machine was a Red Hat Enterprise [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/"&gt;Deliver your applications to edge and IoT devices in rootless containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">851907</post-id><dc:creator>Ilkka Tengvall</dc:creator><dc:date>2021-02-03T08:00:37Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/03/deliver-your-applications-to-edge-and-iot-devices-in-rootless-containers/</feedburner:origLink></entry><entry><title>Using Node.js? The OpenJS Foundation would like to hear your feedback</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FTSEem2GmoI/" /><category term="Node.js" /><category term="node.js survey" /><category term="OpenJS" /><author><name>Bethany Griggs</name></author><id>https://developers.redhat.com/blog/?p=865017</id><updated>2021-02-03T08:00:25Z</updated><published>2021-02-03T08:00:25Z</published><content type="html">&lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://www.surveymonkey.com/r/7BYTZMS"&gt;2021 Node.js User Survey&lt;/a&gt; is now open.&lt;/p&gt; &lt;p&gt;Node.js is an Impact Project under the &lt;a target="_blank" rel="nofollow" href="https://openjsf.org/"&gt;OpenJS Foundation&lt;/a&gt;. The aim of the 2021 Node.js User Survey is to learn who is using Node.js, and how it is being used. It’s also an opportunity for Node.js users to share any feedback with the project. The survey should take around 20 minutes, and the results are anonymized.&lt;/p&gt; &lt;p&gt;You can check out some of the previous year&amp;#8217;s survey results:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://nodejs.org/en/user-survey-report/"&gt;2018 Node.js User Survey Report&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/nodejs.org/blob/206109d457ea0af0cad9c469364bab0be6375d0e/static/documents/casestudies/Nodejs_2017_User_Survey_Exec_Summary.pdf"&gt;2017 Node.js Survey Executive Summary&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://nodejs.org/static/documents/2016-survey-report.pdf"&gt;2016 User Survey Report&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Participating in the survey will help the OpenJS Foundation and Node.js project shape the future of the project around our users. If you’re interested in the future of Node.js, there’s recently been a “Next 10” effort kicked off that is working to define the strategic directions for the next 10 years of Node.js. You can follow the progress (or participate) in this effort at &lt;a target="_blank" rel="nofollow" href="https://github.com/nodejs/next-10"&gt;https://github.com/nodejs/next-10&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Also of interest, check out the recently released &lt;a target="_blank" rel="nofollow" href="https://2020.stateofjs.com/"&gt;State of JS 2020 survey results&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#38;linkname=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F03%2Fusing-node-js-the-openjs-foundation-would-like-to-hear-your-feedback%2F&amp;#038;title=Using%20Node.js%3F%20The%20OpenJS%20Foundation%20would%20like%20to%20hear%20your%20feedback" data-a2a-url="https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/" data-a2a-title="Using Node.js? The OpenJS Foundation would like to hear your feedback"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/"&gt;Using Node.js? The OpenJS Foundation would like to hear your feedback&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FTSEem2GmoI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The 2021 Node.js User Survey is now open. Node.js is an Impact Project under the OpenJS Foundation. The aim of the 2021 Node.js User Survey is to learn who is using Node.js, and how it is being used. It’s also an opportunity for Node.js users to share any feedback with the project. The survey should [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/"&gt;Using Node.js? The OpenJS Foundation would like to hear your feedback&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">865017</post-id><dc:creator>Bethany Griggs</dc:creator><dc:date>2021-02-03T08:00:25Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/03/using-node-js-the-openjs-foundation-would-like-to-hear-your-feedback/</feedburner:origLink></entry><entry><title type="html">4 Easy Steps for Migrating Projects to OpenShift Container Platform</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/vq-elmSEhmE/4-easy-steps-for-migrating-projects-to-openshift-container-platform.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/1Gk5nA3g16M/4-easy-steps-for-migrating-projects-to-openshift-container-platform.html</id><updated>2021-02-03T06:00:00Z</updated><content type="html">This article is a walk through how to take an existing project, in this case I'm using a business automation project, and migrating from running locally on an application server to deploying in a container on OpenShift. The idea is to share four easy steps taking you on a journey from local to cloud native container based application deployments. The base project was an old demo project I had running on JBoss BPM Suite a few years back, polished up and now running on Red Hat Process Automation Manager using Red Hat Enterprise Application Server (EAP). The project will be outlined, followed by installing it locally on your developer machine. After that, you'll need to install the OpenShift Container Platform and I'll show you how using CodeReady Containers. This puts a container platform running on your developer machine, at which point it's a matter of installing the provided business automation operator and pushing the existing project without any changes into the container. You can observe it deploying right on your OpenShift web console or explore the details with the command line client. Ready to get started? STEP 1 - EXAMINING THE PROJECT This article brings back an old demo project, refreshed and polished up now, that is exploring how to use process automation to implement a signal.  The idea is that in this process project we are automating a loan request process where any loan up to 10,000 with a customer over 18 years old is automatically approved. The paths options can be that you might need a loan officer to physically review a loan if it's over 10,000 or it faces auto rejection if the application is made by someone younger than 18 years old. Of these three paths through the process, our fictitious marketing department wants to be notified if it's an existing customer so that they can take action, possibly marketing other services to that customer. The problem is you only want to notify the marketing department if you are sure it's a customer, and that would be anyone over 18 years of age. On top of that you want to pass on as much information as possible on the customer ot the marketing department, so you want to notify them at the end the route taken through the process. The process is not that complicated, and if you trace visually you can see the top end node is for auto rejected, the middle end node is if the loan was reviewed and approved, and the bottom end node is for reviewed applications that get rejected.  The interesting part is at the start of the process where as soon as an application is submitted, it splits to start processing on one route and to wait in a signal event node. If we submit an application that is not auto rejected, it's going to show us that it's waiting on a user review by the loan officer (red outlined node) and waiting to see if it's going to receive a signal (red outlined event node) to add a marketing contact. That wait state is only going to move onwards if we send a signal later in the process, at which time it will trigger the signal event node to proceed onwards. In this next image you see that we approved the loan and that the signal was sent in the final node before ending and the marketing contact was processed. While the initial requirements were to only signal marketing for customer contact, they later decided to track under age applications to offer them the chance to engage with potential future customers. This means we added the signalling to the last reporting node in the reject path. Let's get you started installing this on your local machine and exploring how all this works. STEP 2 - INSTALLING LOCALLY The installation is pretty straightforward and the installation script can be run after unzipping as it provides warnings for any missing software including links to download for free. Just follow the console output instructions until it completes: 1. 2. Add products to installs directory, see installs/README for details and links. 3. Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges, follow displayed instructions to start demo. After start up of the application server you can log in to (for admin and Loan Officer roles use u:erics / p:redhatpam1!) Follow the listed in the readme file. STEP 3 - INSTALLING CONTAINER PLATFORM The easiest way to install a constainter platform on your local developer machine that is exactly like the one you work with in organisations using the various public clouds, is to use the OpenShift Container Platform as provided by the CodeReady Containers product. It's available for a free download and I've outlined the few easy steps needed to , so head on over there and install it now. STEP 4 - INSTALLING TO CONTAINER The final step is now to install both the OpenShift provided operator for business automation and then push this existing project into the container. This can be done by using this project I've set up for you that automates most of it. 1. Ensure you have installed OpenShift with  which was covered in the previous section. 2. 3. Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges. Now log in to the project to start exploring how a process signal to marketing works (the address will be generated by the init script): * CodeReady Container example: ( u:erics / p:redhatpam1! ) That's all there is to it, now you can explore the installation script to see how this was done, explore the OpenShift web console to view the application container setup and deployment, and more. WHAT'S NEXT? Now that you've got a roadmap to migrating your existing projects to a container platform, and not a trivial project either, you can start exploring more of the available operators on your way to full cloud native development. Want to build more process automation projects from scratch? Try this hands-on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/vq-elmSEhmE" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/1Gk5nA3g16M/4-easy-steps-for-migrating-projects-to-openshift-container-platform.html</feedburner:origLink></entry><entry><title type="html">Quarkus Insights Q&amp;amp;A</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Mt-VXx1nVBU/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-insights-qanda/</id><updated>2021-02-02T00:00:00Z</updated><content type="html">On the next Quarkus Insights episode, we are trying something new. We will cover the most often asked questions we have seen and any question tagged with #quarkusinsights on our various social media presences: Twitter, Facebook, LinkedIn or on the youtube event directly. If you have a question about Quarkus...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Mt-VXx1nVBU" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-insights-qanda/</feedburner:origLink></entry><entry><title>How Red Hat ported OpenJDK to 64-bit Arm: A community history</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lrhdBnHEIQ0/" /><category term="Java" /><category term="Linux" /><category term="Mac" /><category term="Open source" /><category term="Windows" /><category term="64-bit ARM" /><category term="AArch64" /><category term="OpenJDK" /><category term="RHEL" /><category term="x86" /><author><name>Andrew Haley</name></author><id>https://developers.redhat.com/blog/?p=827387</id><updated>2021-02-01T08:00:42Z</updated><published>2021-02-01T08:00:42Z</published><content type="html">&lt;p&gt;It has been quite a year for Arm Ltd., the firm that designs reduced instruction set computing (RISC) architectures for computer processors. The news that Arm-based computers will be important for the foreseeable future has even reached the &lt;a target="_blank" rel="nofollow" href="https://www.nytimes.com/2020/12/01/technology/amazon-apple-chips-intel-arm.html"&gt;mainstream media&lt;/a&gt;. At the end of 2019, Amazon Web Services announced Arm-based Graviton2 servers. In June 2020, Apple announced its plans to move Macintosh computers over to Apple silicon—which means Arm.&lt;/p&gt; &lt;p&gt;For those of us who have worked for years on Arm servers, this shift has been a long time coming.&lt;/p&gt; &lt;h2&gt;In the beginning&lt;/h2&gt; &lt;p&gt;Wind back to a day in 2011. I was having lunch at The Wrestlers (the Cambridge U.K. tech community&amp;#8217;s favorite Thai eatery) with Jon Masters, Red Hat&amp;#8217;s lead Arm architect. He had exciting news to share: Arm would produce a 64-bit architecture, and Red Hat was going to port &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) to it. We&amp;#8217;d need to solve quite a few problems to get this done, but one was particularly difficult. The software then available for the new 64-bit architecture did not include &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt;. Java is a key component of much enterprise software, so this news was a pretty big deal.&lt;/p&gt; &lt;p&gt;Someone would have to write a port. I had heard that two experts could write a bare-bones port of &lt;a href="https://developers.redhat.com/products/openjdk/overview"&gt;OpenJDK&lt;/a&gt; in about a year, but that was all I knew. If my team were going to do it, we&amp;#8217;d have to learn on the job.&lt;/p&gt; &lt;p&gt;I was thrilled at the prospect of getting my teeth into such a substantial piece of work, but how could Red Hat justify starting this big project with no guarantee of success? I argued that unless we did it, we&amp;#8217;d have to pay someone. That would cost lots, so why not save money by doing it ourselves? It would be good publicity, and we&amp;#8217;d be able to build alliances. But there was another, deeper reason to keep it in-house. We&amp;#8217;d been building up a support team for OpenJDK. By writing an entire port, we&amp;#8217;d gain experience that we could not get any other way. Red Hat&amp;#8217;s management agreed (and has consistently supported the project ever since), so we were good to go.&lt;/p&gt; &lt;p&gt;I was determined to be one of the engineers on this project, but I couldn&amp;#8217;t do it alone. Fortunately, Andrew Dinn was about to join our Java team. He&amp;#8217;d worked on Java for a long time and had experience writing compilers for Lisp machines and logic languages. He&amp;#8217;d be a good fit.&lt;/p&gt; &lt;p&gt;One thing worried me: What if someone else did a port first? Then the whole effort might be wasted, along with any hope of glory. The only way to prevent that disaster was to gain first-mover advantage and do the work in public. Get it done fast, do it well, and make it free. Build it, and they will come.&lt;/p&gt; &lt;h2&gt;Starting the project&lt;/h2&gt; &lt;p&gt;We did have one problem—or rather, two. First, there was no AArch64 processor in existence. Also, persuading Arm Ltd. to give us the detailed information we needed was not easy. Persistence and help from Arm&amp;#8217;s Philippe Robin solved the documentation problem, but the lack of hardware was more difficult. It is possible to run all of OpenJDK under simulation, but the simulators at the time were painfully slow. What&amp;#8217;s worse, OpenJDK has to call out to the operating system. We would need to bootstrap all of &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; on the simulator before we could fire up Java.&lt;/p&gt; &lt;p&gt;Andrew Dinn remembers us being at breakfast at a conference when I excitedly told him that, while in the shower that morning, I&amp;#8217;d figured out what to do. We&amp;#8217;d use a simple, functional instruction set simulator, but just for the AArch64 code that we generated ourselves. The rest of the OpenJDK JVM is C++. We could run that natively at full speed on an Intel x86-based PC. Every call from C++ to Java would enter the simulator, and every call from Java back to C++ would leave the simulator and return to x86 code. But where would we get an AArch64 simulator library? &amp;#8220;We&amp;#8217;ll write one,&amp;#8221; I said. &amp;#8220;It&amp;#8217;s a RISC. How hard can it be?&amp;#8221;&lt;/p&gt; &lt;p&gt;We started in June of 2012. It took Andrew Dinn a little while to write the simulator, while I got on with writing the assembler and initial startup code. After a couple of months, we were executing Java bytecodes. The idea of writing our own simulator had been inspired. We could create complex breakpoint conditions and even record instruction traces so that we could see the instruction history when the JVM crashed. As a result, the initial porting went quickly. Looking back at the logs, I see an entry of &amp;#8220;Enough for Hello, World!&amp;#8221; on Oct 4, 2012. This was an important day: To get as far as outputting &amp;#8220;Hello, World!&amp;#8221; to the console, Java has to execute about three-quarters of a million bytecodes without crashing, and exercise much of the virtual machine.&lt;/p&gt; &lt;h2&gt;And then there were three&lt;/h2&gt; &lt;p&gt;By the summer of 2013, three of us were working on the project. Edward Nevill, a Java expert formerly of Arm Ltd., joined the project from Linaro. He was the first to get actual hardware. I was so comfortable with our little AArch64 simulator that I was very happy for someone else to debug our work on the real machine. I expected it to be a painful process. But, apart from a small problem with flushing the instruction cache and an issue with floating-point flags, it all worked! I was astonished. We&amp;#8217;d written our own simulator, compiler, and assembler from Arm&amp;#8217;s documentation. We&amp;#8217;d had no independent verification, but we&amp;#8217;d got it right.&lt;/p&gt; &lt;p&gt;Edward was a tremendous help, and by the start of 2014, we had a working port. Red Hat began shipping early releases to our partners, we and others carried on fixing bugs and improving performance, and on March 2, 2015, the AArch64 port was part of the main OpenJDK project. Oracle was great and helped and encouraged us through the tricky integration process.&lt;/p&gt; &lt;h2&gt;Consolidation and the (very) long tail&lt;/h2&gt; &lt;p&gt;There&amp;#8217;s a considerable difference between a working JVM and one that&amp;#8217;s really good. I don&amp;#8217;t know how much time has been spent on Intel/x86 OpenJDK, but it must be dozens of engineer years. It was a real challenge for us to make the AArch64 port competitive, but we had help. People from the AArch64 silicon producers and other companies joined us, and now people from all around the world are working on the port.&lt;/p&gt; &lt;p&gt;This is where Red Hat&amp;#8217;s open and collaborative approach really pays off. By forming partnerships with others, we gain a big multiplier over purely in-house software development.&lt;/p&gt; &lt;p&gt;But that&amp;#8217;s not the whole story. We&amp;#8217;d heard that Oracle was running Java on 64-bit Arm, and I wondered if it was our port. As it turned out, the port was proprietary, based on the (32-bit) Arm port Oracle already had. I was worried that Java&amp;#8217;s originator would get much better performance than we had. Eventually, someone who had used Oracle&amp;#8217;s port kindly assured me that I had nothing to worry about. I found it strange that Oracle wrote a port of its own, however. The company had permission from the beginning to use all of our code. Why write it again?&lt;/p&gt; &lt;p&gt;Eventually, Oracle freed both of its Arm 32- and 64-bit ports. That left us with two AArch64 ports in OpenJDK. Then, on November 12, 2020, Oracle &lt;a target="_blank" rel="nofollow" href="https://blogs.oracle.com/java-platform-group/update-on-64-bit-arm-support-for-oracle-openjdk-and-oracle-jdk"&gt;announced&lt;/a&gt; that it had decided to focus its resources going forward on a single 64-bit Arm port: The AArch64 port we&amp;#8217;d started at Red Hat. The 64-bit Arm support in Oracle&amp;#8217;s maintenance release of JDK 8 is now based on our port, as well.&lt;/p&gt; &lt;p&gt;Recently, with much fuss, Apple announced the Apple M1 chip, an implementation of AArch64. OpenJDK was ready for that processor and had been for five years. However, there is a layer of OpenJDK that&amp;#8217;s specific to each OS-CPU combination. Somebody had to do that work, and we soon had two volunteers: Microsoft and Azul, who worked on it together. Microsoft also ported the OS-CPU layer to Windows/AArch64.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;So, why did all this happen? The OpenJDK developer community made the decision. I believe that&amp;#8217;s because our little team stepped up with a working port early, got it into the OpenJDK mainline, and welcomed everyone who wanted to participate. We kept as many discussions as possible open. People volunteered, and we became a community. We achieved far more with this community than we ever could have hoped to do on our own. But none of it would have happened if we had not released that working port back at the start of 2014.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#038;title=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" data-a2a-url="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/" data-a2a-title="How Red Hat ported OpenJDK to 64-bit Arm: A community history"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/"&gt;How Red Hat ported OpenJDK to 64-bit Arm: A community history&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lrhdBnHEIQ0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;It has been quite a year for Arm Ltd., the firm that designs reduced instruction set computing (RISC) architectures for computer processors. The news that Arm-based computers will be important for the foreseeable future has even reached the mainstream media. At the end of 2019, Amazon Web Services announced Arm-based Graviton2 servers. In June 2020, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/"&gt;How Red Hat ported OpenJDK to 64-bit Arm: A community history&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">3</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">827387</post-id><dc:creator>Andrew Haley</dc:creator><dc:date>2021-02-01T08:00:42Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/</feedburner:origLink></entry></feed>
